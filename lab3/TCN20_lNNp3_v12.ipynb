{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 3: PyTorch - построение моделей\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин__ e-mail: SVMakrushin@fa.ru \n",
    "\n",
    "Финансовый универсиет, 2021 г. \n",
    "\n",
    "При подготовке лекции использованы материалы:\n",
    "* ...\n",
    "\n",
    "v 0.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v1.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Импорты\n",
    "\n",
    "* Нужно установить PyTorch (см предыдущую лекцию!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "#---------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import normalize\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Загрузка и преобразование данных](#загрузка)\n",
    "* [Тензоры и опреации с ними в PyTorch](#тензоры)\n",
    "    * [Создание тензоров](#создание-тензоров)\n",
    "    * [Операции с тензорами](#операции-тензоры)    \n",
    "        * [Арифметические операции и математические функции:](#aрифметические)        \n",
    "        * [Операции, изменяющие размер тензора](#размер)        \n",
    "        * [Операции агрегации](#агрегации)        \n",
    "        * [Матричные операции](#aрифметические)                \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Загрузка и преобразование данных <a class=\"anchor\" id=\"установка\"></a>\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Принципиальная логика организации работы с данными в PyTorch:\n",
    "1. Создается объект `Dataset`\n",
    "    * `Dataset` обеспечивает доступ данным (с помощью интерфеса )\n",
    "    * в параметр `transform` конструктора `Dataset` передается вызываемый объкт, обеспечивающий трансформацию исходных данных \n",
    "2. `Dataset` передается в `DataLoader`\n",
    "    * `DataLoader` обеспечивает загрузку данных батчами, распараллеливает загрузку данных и т.п.\n",
    "    \n",
    "см.: \n",
    "* общая логика: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "* трансформеры: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "* DataLoader и то что его окружает: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset Types__\n",
    "\n",
    "The most important argument of DataLoader constructor is __dataset__, which indicates a dataset object to load data from. PyTorch supports two different types of datasets:\n",
    "* map-style datasets\n",
    "    * the `__getitem__()` and `__len__()` protocols, and represents a map from (possibly non-integral) indices/keys to data samples.\n",
    "    * For example, such a dataset, when accessed with `dataset[idx]`, could read the `idx`-th image and its corresponding label from a folder on the disk.\n",
    "    * Note: `DataLoader` __by default constructs a index sampler that yields integral indices__. To make it work with a map-style dataset with non-integral indices/keys, a custom sampler must be provided.\n",
    "* iterable-style datasets.\n",
    "    * IterableDataset implements the `__iter__()` protocol, and represents an iterable over data samples. This type of datasets is particularly suitable for cases __where random reads are expensive or even improbable__, and where the batch size depends on the fetched data.\n",
    "\n",
    "* see: https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import datasets\n",
    "raw_data = datasets.load_wine()\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация о датасете WINE: https://archive.ics.uci.edu/ml/datasets/wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "raw_data = datasets.load_wine()\n",
    "raw_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]]\n",
      "Values:  Counter({1: 71, 0: 59, 2: 48})\n"
     ]
    }
   ],
   "source": [
    "print(raw_data['feature_names'])\n",
    "print(raw_data['data'][:3])\n",
    "print('Values: ', Counter(raw_data['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header ['Wine', 'Alcohol', 'Malic.acid', 'Ash', 'Acl', 'Mg', 'Phenols', 'Flavanoids', 'Nonflavanoid.phenols', 'Proanth', 'Color.int', 'Hue', 'OD', 'Proline']\n",
      "line: 0 | ['1', '14.23', '1.71', '2.43', '15.6', '127', '2.8', '3.06', '.28', '2.29', '5.64', '1.04', '3.92', '1065']\n",
      "line: 1 | ['1', '13.2', '1.78', '2.14', '11.2', '100', '2.65', '2.76', '.26', '1.28', '4.38', '1.05', '3.4', '1050']\n",
      "line: 2 | ['1', '13.16', '2.36', '2.67', '18.6', '101', '2.8', '3.24', '.3', '2.81', '5.68', '1.03', '3.17', '1185']\n",
      "Values:  Counter({'2': 71, '1': 59, '3': 48})\n"
     ]
    }
   ],
   "source": [
    "with open('./data/wine/wine.csv') as wine_csv:\n",
    "    # load data:\n",
    "    wine_data = list(csv.reader(wine_csv, delimiter=','))\n",
    "\n",
    "wine_data_it = iter(wine_data)\n",
    "print('Header', list(next(wine_data_it)))\n",
    "for line_n, line in enumerate(it.islice(wine_data_it, 3)):\n",
    "    print(f'line: {line_n} | {line}')\n",
    "    \n",
    "print('Values: ', Counter([l[0] for l in wine_data[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a custom Dataset:\n",
    "# inherit Dataset\n",
    "# implement __init__ , __getitem__ , and __len__  \n",
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None, verbose=False):\n",
    "        # load dataset from CSV file (first row: labels)\n",
    "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "\n",
    "        # note that we do not convert to tensor here\n",
    "        self.n_samples = xy.shape[0] # number of samples        \n",
    "        self.y_data = xy[:, [0]] # y in first column (shape: N*1)       \n",
    "        self.x_data = xy[:, 1:]\n",
    "        if verbose:\n",
    "            print(f'y shape:{self.y_data.shape()}')\n",
    "            print(f'x shape:{self.x_data.shape()}')            \n",
    "\n",
    "        # save transformer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        # apply transformer:\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transformation:\n",
      "X: [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] <class 'numpy.ndarray'> (13,)\n",
      "y: [1.] <class 'numpy.ndarray'> (1,)\n"
     ]
    }
   ],
   "source": [
    "print('Without Transformation:')\n",
    "dataset = WineDataset()\n",
    "\n",
    "X, y = dataset[0]\n",
    "print('X:', X, type(X), X.shape)\n",
    "print('y:', y, type(y), y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Transforms__\n",
    "\n",
    "Часто необходим некоторый препроцессинг данных получаемых из данных, оформленных в виде `Dataset`.\n",
    "\n",
    "Мы будем реализовывать препроцессинг в виде __callable classes__ вместо обычных функций, это позволит не передавать параметры трансформации при каждом вызове преобразований. Для создания вызываемых классов в них необходимо реализовать функцию вызова `__call__` и, если необходимо, конструктор `__init__`, через который можно передавать параметры трансформациия:\n",
    "\n",
    "```python\n",
    "tsfm = Transform(params)\n",
    "transformed_sample = tsfm(sample)\n",
    "```\n",
    "\n",
    "* В `torchvision.transforms` находится много готовых трансформеров (см.  https://pytorch.org/docs/stable/torchvision/transforms.html ), большая часть ориентирована на преобразование изображений, но есть несколько универсальных инструментов:\n",
    "    * `torchvision.transforms.Compose` - позволяет создать трансформер из нескольких трансформеров, применяемых последовательно. Пример:\n",
    "    \n",
    "```python\n",
    "transforms.Compose([\n",
    "    transforms.CenterCrop(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transforms\n",
    "# implement __call__(self, sample)\n",
    "class ToTensor:\n",
    "    # Convert ndarrays to Tensors\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Tensor Transform\n",
      "X: tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) <class 'torch.Tensor'> torch.Size([13])\n",
      "y: tensor([1.]) <class 'torch.Tensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print('With Tensor Transform')\n",
    "dataset = WineDataset(transform=ToTensor())\n",
    "\n",
    "X, y = dataset[0]\n",
    "print('X:', X, type(X), X.size())\n",
    "print('y:', y, type(y), y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulTransform:\n",
    "    # multiply inputs with a given factor\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    # multiply imputs by factor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Tensor and Multiplication Transform\n",
      "X: tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
      "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
      "        4.2600e+03]) <class 'torch.Tensor'> torch.Size([13])\n",
      "y: tensor([1.]) <class 'torch.Tensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print('With Tensor and Multiplication Transform')\n",
    "# create composed transformer:\n",
    "composed_tfms = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
    "dataset_mul = WineDataset(transform=composed_tfms)\n",
    "\n",
    "X, y = dataset_mul[0]\n",
    "print('X:', X, type(X), X.size())\n",
    "print('y:', y, type(y), y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеется модуль `torchvision.transforms.functional` (обычно импортируется как `python import torch.nn.functional as F`) в котором есть множество готовых трансформеров (в основном для преобразования изображений):\n",
    "* подробнее см.: https://pytorch.org/docs/stable/torchvision/transforms.html \n",
    "\n",
    "```python\n",
    "class Normalize(object):\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "        \"\"\"\n",
    "        return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DataLoader__\n",
    "\n",
    "`DataLoader` подгружает данные, предоставляемые классом `Dataset`, во время тренировки и группирует их в батчи. \n",
    "Он дает возможность указать `Sampler`, который выбирает, какие примеры из датасета использовать для тренировки. Этот параметр можно использовать для разделения данных на training и validation.\n",
    "\n",
    "`torch.utils.data.DataLoader` это итератор, который обеспечивает:\n",
    "* организацию данных в батчи (batching the data)\n",
    "* перемешивание данных (shuffling the data)\n",
    "* параллельную загрузку данных с использованием multiprocessing workers.\n",
    "\n",
    "Основные параметры:\n",
    "* `dataset` (Dataset) – dataset from which to load the data.\n",
    "* `batch_size` (int, optional) – how many samples per batch to load (default: 1).\n",
    "* `shuffle` (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).\n",
    "* `sampler` (Sampler, optional) – defines the strategy to draw samples from the dataset. If specified, shuffle must be False.\n",
    "* `num_workers` (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)\n",
    "\n",
    "Подробнее см. в: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole dataset with DataLoader\n",
    "# shuffle: shuffle data, good for training\n",
    "# num_workers: faster loading with multiple subprocesses\n",
    "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([[3.4839e+06, 5.1642e+05, 7.0255e+05, 4.4040e+06, 2.6739e+07, 7.8643e+05,\n",
      "         8.4673e+05, 8.1265e+04, 4.3516e+05, 1.5729e+06, 2.8049e+05, 7.4449e+05,\n",
      "         3.3292e+08],\n",
      "        [1.4879e+07, 1.6672e+06, 2.6005e+06, 1.7302e+07, 1.1325e+08, 3.4603e+06,\n",
      "         4.1209e+06, 3.3554e+05, 1.9504e+06, 9.1226e+06, 1.2897e+06, 2.9570e+06,\n",
      "         1.7616e+09],\n",
      "        [3.3345e+06, 4.5875e+05, 5.9769e+05, 5.8982e+06, 2.2020e+07, 3.6176e+05,\n",
      "         4.6137e+05, 1.2583e+05, 4.2729e+05, 8.6508e+05, 2.3069e+05, 6.3439e+05,\n",
      "         1.2793e+08],\n",
      "        [3.1457e+06, 3.9584e+05, 6.3439e+05, 5.7672e+06, 2.2544e+07, 3.8011e+05,\n",
      "         3.2768e+05, 1.3107e+05, 4.2729e+05, 9.4372e+05, 2.7525e+05, 6.9468e+05,\n",
      "         1.1796e+08]]) torch.Size([4, 13])\n",
      "labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print('features:', features, features.shape)\n",
    "print('labels:', labels, labels.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Dummy Training loop\n",
    "num_epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):        \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ’®¬ ў гбва®©бвўҐ E Ё¬ҐҐв ¬ҐвЄг Data\n",
      " ‘ҐаЁ©­л© ­®¬Ґа в®¬ : EE2C-D1DD\n",
      "\n",
      " ‘®¤Ґа¦Ё¬®Ґ Ї ЇЄЁ E:\\YandexDisk\\Python\\Ipynb\\ML_DL_2021\\lec03_PyTorch_p3\n",
      "\n",
      "08.03.2021  23:04    <DIR>          .\n",
      "08.03.2021  23:04    <DIR>          ..\n",
      "04.02.2021  16:08    <DIR>          .ipynb_checkpoints\n",
      "08.03.2021  23:04           199я469 TCN20_lNNp3_v12.ipynb\n",
      "               1 д ©«®ў        199я469 Ў ©в\n",
      "               3 Ї Ї®Є  336я128я081я920 Ў ©в бў®Ў®¤­®\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Нормализация\n",
    "\n",
    "<center>     \n",
    "    <img src=\"./img03/preprocessing_2.png\" alt=\"Предобработка данных\" style=\"width: 400px;\"/>\n",
    "    <strong>Предобработка данных</strong>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "\n",
    "composed_tfms = transforms.Compose([\n",
    "            ToTensor() \n",
    "            # don't use Normalize() for the first time\n",
    "        ])\n",
    "\n",
    "dataset = WineDataset(transform=composed_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axes.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points = dataset.x_data\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "use_lim = True\n",
    "lim = 25.0\n",
    "\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(axes.shape[1]):      \n",
    "        ax = axes[i, j]\n",
    "        if use_lim:\n",
    "            ax.set_xlim([-lim, lim])                \n",
    "            ax.set_ylim([-lim, lim])\n",
    "        ax.scatter(points[:, j], points[:, i], s = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3000614e+01, 2.3363481e+00, 2.3665185e+00, 1.9494946e+01,\n",
       "       9.9741570e+01, 2.2951121e+00, 2.0292699e+00, 3.6185396e-01,\n",
       "       1.5908992e+00, 5.0580897e+00, 9.5744956e-01, 2.6116843e+00,\n",
       "       7.4689325e+02], dtype=float32)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем среднее по всему датасету:\n",
    "wine_mean = dataset.x_data.mean(axis=0)\n",
    "wine_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.0954307e-01, 1.1140037e+00, 2.7357230e-01, 3.3301697e+00,\n",
       "       1.4242310e+01, 6.2409055e-01, 9.9604911e-01, 1.2410324e-01,\n",
       "       5.7074893e-01, 2.3117647e+00, 2.2792861e-01, 7.0799321e-01,\n",
       "       3.1402167e+02], dtype=float32)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем стандартное отклонение по всему датасету:\n",
    "wine_std = dataset.x_data.std(axis=0)\n",
    "wine_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест для фичи 0:\n",
    "\n",
    "# r = (dataset.x_data - wine_mean)/wine_std\n",
    "# r[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize:\n",
    "    def __init__(self, mean, std, inplace=False):\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        \n",
    "        if not self.inplace:\n",
    "            inputs = inputs.clone()\n",
    "        inputs.sub_(self.mean).div_(self.std)\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "composed_tfms = transforms.Compose([\n",
    "            ToTensor(), \n",
    "            Normalize(wine_mean, wine_std)\n",
    "        ])\n",
    "\n",
    "train_ds = WineDataset(transform=composed_tfms)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([[ 1.5186, -0.5622,  0.2320, -1.1696,  1.9139,  0.8090,  1.0348, -0.6596,\n",
      "          1.2249,  0.2517,  0.3622,  1.8479,  1.0130],\n",
      "        [ 0.2463, -0.4994, -0.8280, -2.4908,  0.0181,  0.5686,  0.7336, -0.8207,\n",
      "         -0.5447, -0.2933,  0.4060,  1.1135,  0.9652],\n",
      "        [ 0.1969,  0.0212,  1.1093, -0.2687,  0.0884,  0.8090,  1.2155, -0.4984,\n",
      "          2.1360,  0.2690,  0.3183,  0.7886,  1.3951],\n",
      "        [ 1.6916, -0.3468,  0.4879, -0.8093,  0.9309,  2.4914,  1.4665, -0.9819,\n",
      "          1.0322,  1.1861, -0.4275,  1.1841,  2.3346]]) torch.Size([4, 13])\n",
      "labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print('features:', features, features.shape)\n",
    "print('labels:', labels, labels.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n",
      "Epoch: 1/1, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
      "Epoch: 1/1, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Dummy Training loop\n",
    "num_epochs = 1\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n",
    "\n",
    "inputs_points = None\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets) in enumerate(train_dl):        \n",
    "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
    "        # Run your training process\n",
    "        if inputs_points is None:\n",
    "            inputs_points = inputs.clone()\n",
    "        else:\n",
    "            inputs_points = torch.cat((inputs_points, inputs))\n",
    "        \n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([178, 13])"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_points.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тест для фичи 0:\n",
    "\n",
    "# inputs_points[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAI/CAYAAACvYncDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3Qd5X0v/O9PF8uWLFsCya8VLMmYShgjUlHLcVKIm5UoWMcxwV3pMRzaQA8hLufAWuKclhaSmjbovAdn+W0bnxdOCDVpSIsXcEpDatexQbmUGIJiKRb4iowNkmzk1zLeulg37y097x97z3j2aPZ1ZrT3nvl+1vKyLlszY83Xz/z2M8/zjCilQERERETOy8v0ARARERF5FQstIiIiIpew0CIiIiJyCQstIiIiIpew0CIiIiJyCQstIiIiIpcUZGKnFRUVavny5ZnYNc2Rrq6uC0qpSjf3wRx5n9s5Yoa8j20ROcFOjjJSaC1fvhydnZ2Z2DXNERHpdXsfzJH3uZ0jZsj72BaRE+zkiLcOiYiIiFzCQouIiIjIJSy0iIiIiFzCQouIiIjIJSy0iIiIiFzCQouIiIjIJY4VWiKSLyKHRGSPU9sk/2GOyC5miJzAHJFTnOzRagVw3MHtkT8xR2QXM0ROYI7IEY4UWiKyDMCXAOx0YnvkT8wR2cUMkROYI3KSUz1a3wHw5wBmHNoe+RNzRHYxQ+QE5ogcY7vQEpGNAM4rpboSvG6LiHSKSOfg4KDd3ZLHMEdkFzNETmCOyGlO9GjdAuDLIvIhgBcBfF5E/sn8IqXUs0qpJqVUU2Wlq8/3pNzEHJFdzBA5gTkiR9kutJRSjymllimllgO4C8DPlFJ/ZPvIyFeYI7KLGSInMEfkNK6jRUREROSSAic3ppT6BYBfOLlN8h/miOxihsgJzBE5gT1aRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC6xXWiJSLWI/FxEjovIURFpdeLAKD1dvQHc81wHunoDmT6UlDBHuXvusoXfM8T8OMNrOWIuMs+JHq0QgD9VSt0A4NMAHhSRVQ5sl1LU1RvA/c8fxBsnL2BHe0+mDydVvs/RjvYevHHyAu5//iAbxfT4OkNafhL93+eFN6GcyVEy5zLZXJB7bBdaSqkBpdRvIh+PAjgO4Bq726XU7WjvQWA8iPLiQrQ212f6cFLCHAGtzfUoLy5EYDzIRjENfs9Qa3M91tVVJPy/zwtvfLmUo2TOZbK5IPcUOLkxEVkO4GYAHU5ul5Kj/Udqba7H6tryDB9N+vyao9W15dh57xrsaO9ho2iTHzO0urYcP/za2oSvM7YTFF+25yiZc5lsLsg9opRyZkMiCwH8O4D/Wyn1Lxbf3wJgCwDU1NSs7u3tdWS/lJ1EpEsp1ZTGzzFHpEsnR8wQGbEtIiekmyPAoVmHIlII4BUAL1gFEgCUUs8qpZqUUk2VlZVO7JY8hjkiu5ghcgJzRE5yYtahAHgOwHGl1N/aPyRK5OEXD2H5o/+Gh188lOlDcQxzdMWujj7c9Ff78cW/+YXtAct+GvjMDM1mPv/Gz2N97He5mKNkzl+s12hf39XRxwy4xIkerVsAfBXA50WkO/JngwPbJQtdvQG82v0RAOh/e4Tvc6Q1eE/uPYbRqRBODo6hbfdRW9v02cBn32fIzHz+jZ/H+jiWXR19uPmJ17Cro2+uDj9Tci5HyZy/WK/Rvr59/4mU2gqninM/FPm2B8MrpQ4AEAeOhRLYtvc4nnnjtP75ktKiDB6Ns5gj4NFX3sXJ85ewpLQI45enMa0AiL1fiXmwbFdvQB9sn8sTJqwwQ7O1NtdjZCKIkckQunoDUXl479woDp8dRktDFQBEfWxl+/4TCIwHsX3/Cdy9tmZOjj8TcjFHyfw/j/WaloYqjEwEMXZ5GrVXFSc9SUIr0ADYGmzv1HayGVeGzxG7OvqiiqzG6jJ8949WZ/CIyEldvQGcHrwEAPj40hTaNt2EdXUV2Lpx1azXpfLuT5txpDW2XKvLX1bXlmPRgkJ09w9hR3tPVB7+4cBpBMaD+LvX38PjPz6CwHgQ+44MxNzWI+tXory4EI+sXzmH/wJKRqz/58beKeNrjGsu7jsyAIjg5PlLgEjMN2DmtqeloQrlxYVxi/Nk+GH5CRZaOWDb3uP4xo8O658X5efh1Qdv8VyPhF9pjd50ZALwtAL2HRlAa3M92vYcw6anDuiNm91bga3N9SgtykdgPGj7tiTlhpaGKpQW5WNgeDJqPNbZoUkAwOClywjNKBTkSdyL3d1ra7Dz3jXYd2SARXqWS1S8zFpzMbL6wKnzo1Hn1lhcte0+ijdOXtDbjX1HBhIW54l4uYfdyNF1tMh55tuFeQL81ZdvzOARkdO0Ri9fgE+ULcDVJfPQ2lyPHe096O4fAgC07TmGVx+8xfYaSKtry3HdktLwdm3elqTsZLx4AeFbfqNT0xg9f0kv0N84eQF1SxbiwqUp/F59Jf69ZxCPrF8ZdbGzugj64TaPFyRaO8t8C/nU4BiKC/MwOjWtn/Md7T0YmQzpbZDeXkT+dmI9Nr/kiYVWltt54AP94+ryBfjOXTd7uvL3o9bmehw+O4zAeBD9gQlcW1GC1bXlaG2ux6G+AEanpvV3nE4sPrh14youiuphxosXAATGgygtysd1S0qjznmiXgSriyAXO/UGYzty//MHMToVQmlRAdbVXaUXWW+cvIDGZYujesaM7YYTbZFf8sRbh1lq297juO6xf8OCwjzkC/DAuhX45V98nkWWB2krwtdVlqC4MB8fXBjDpqcOAAB+cN/a8Fit253rxTSP54jHDzOCcp35HLU216Nx2WIMDE9iYHgSjcsW4wf3rdWHGyRz/rt6AxiZDKFx2eKoi2Aq2aHsZM7LnU3VKMgT/OHaGv3cauOvNq+58jXzuXeibfBLnlhoZaFNTx3AM2+cxrQCRqemcctvVeDRDTdk+rDIYcb1a9r2HMPZoQmMB6fRH5hA95lhtO055lpDlGwj6bPlIXKS+RxpA+BPnr80a4Bzsmsmte0+iu7+IZwavIT3zo3GXX+JRXh2M58nc17e/uAiQjMKb39wUX+9NsPUavyVtsxH64uHwmO29hxz9Pi8iLcOs8w9z3Wg+8yw/nlRfvwBqpS7tAZPvz1oMjYZjPvzdgaSJjs2wi9d+7nM6hy1Ntej88OLGA/O4MLoJO55riPqltChviGMToUwMhnCqw/eMnujkXE4o1PT+kX3UN8Qrqsswdbbb8Tq2nLfjK/JdebzZM6L1s70nBvRB71rt5ut/t+H1/mbxvBEpH2yeIxfKm2TH3LEQiuL3PNcR9TYioVF+Xj+Pu93q/qVtsbR8YFRAOGFe4xN1mRoJu7PWzVQyTZwWgPa0lClX4StXh9rHIZfZgvlAqtztLq2HNeUF+Pk+Uu4OBbEmaELGBiexLnhCdQtWQgohdHBUNQss7bdRwERbN24Cls3rgr3VCiFzWtq9GJL62l1YmIGzQ3zeTLnpWR+IQBgPDiDO7/3K1xVEv586eIFlv+3ly5egNHzl3D1wnkITSt8esXVs9oQrW0aGJ7EhUtTeGT9yphrr/khR7x1mCW27T0eVWQV5AFHvtXCi5hHaYUKAExNhwuq36osCV8EI4bGL8fdhnEKt9b93rbnWFK3+rTGdt+RgZivj9elz1uKc8PObZWSovD76GvKF2BdXQXOBsYxOjWNc8MT2PYHv43y4kJ9ltmO9h50nxlGd/8Q7n/+IADg1QdvwasP3aov61BcmA8AGJsKAfDP+JpcZ3WejLnaunEVGpctRr4AoRmFC5cuW75Os+0rn8S6ugqULZiHwHgQL3T0zWoLtLbp3PCEvshtKsfnNSy0ssDDLx6KWsIBAJ6446YMHQ3NBb03SgSN1WVoXLYYX7jh/9IXLc0X4LENqyx/Vmv8AOgNlL49pVJa/C/eejvxiik/LDKYDewUtFs3rsK6ugr851uuBQAsjPRclBXP0ydgNFaXYWQiiJaGKjQuW6yvsWa1v/zI1aJkXn76/yDKCuZcLVpQiK9/dgXKiwvxicXzAYTPs/l1xp5sLQeLiwtnLVyqFU+PbVgVd5FbP4zPAnjrMONu3fZTnIksHAgAy8oXYAeXcPA8Y3e5dq5Xbf2Jvmjp1QuLYna1x5p2PzA0gVODY3hsww1Rg5/j3eKLN0U7Xpe+E1O7KbFUb6sYH6uiLXqr5aW0KHxhvLpkXlSPaveZYSxaMIBXH7o1Ki+7OvrwP/YcBSC4pnwBRqemUZAn2LzGu4/f8QtjroztyaHHb5u1Dpv2Om1h5cB4EIfPDuPOpmr0XhwHEF5C5OXO/llt1vVLS3HTNYtx/dJSAFfyuapqEV7q7EfFwqLwhA14d3wWwEIrox5+8VBUkbWp8RP4zl03Z/CIaK5YFypXFhD9+NJUzJ+1uviuri3HhbHLGJ0KRT2LTmtEtYbxpc7+mOMlzEUZi6nMS+YcGM+b8XwHxsODlY3j8czFV+OyxWhctlh/FqK2v67eAB7/8RGEZsKV/7nhCZQXF+oz0cz54Zi93GLMVaIxXNrHm546oC+sHBgP4qXOfgTGgwhFhj5YDYrXx2oNTeDC2GVUlMzDycExvHXqY4RmFELTM7Py50W8dZgh2/Yex6vdH+mfLyubzyLL4xJ1k//lxlUozA8XW7f/9idS3r7Vs+ham+v1C+TOAx/EHS/BcVe5yXjetFu6j6xfqd/aNV44D58dxnvnRvXXbb39xqhnIRq3qRVZRQV5eGzDKuy8d01at5kpd8RtoyIzUVdULsS6ugrc2VSN8uJC/OHa2phr/eljtUamEBgP4tzIFNbVVeD+W69FeXEhHtuwyjJ/XsMerQwwzy5kT5Y/JDONWXtT+OGFsZizAWNt5+61Nbh+aSl2tPfg+qWleq/UznvXRHXXa4WYuRfCD7N/vKi1uR4jkyGMRKbba5nQsqCdX23m4OM/PoKX/uQzcVd7Nz6tYO21V83allFXbwAjE0E0VpcxOzlE+/8/MhGeTToyEcSpwbGYy34YnyixurZc7+F6+/THePWhW2dt11jk7+row/b9J6J607W1IbXbil7OjiM9WiLSIiLvicj7IvKoE9v0qocji7xpHli3gkVWhNdzlGgA+fb9J/RehLHL0zF7CLRVm42DTzVaEXb/8wf1d6VaY/fohhuiHgpstdBlrs/+8XqGrGjnS1t6QaOd3zu/9yvs6ujDI+tXoiBPEJpRUbmyOu9aga7lNV6PlTZjsffjMRf/lXMrF3JkdyC5cULOuroKQASjkRmlY5PBqG1b3ho2Pfsw3sznu9fW4NDjt1kOWfBCu5OI7UJLRPIBPA3gPwBYBeA/iYj1dCmfe/jFQ1G3C9fVccV3jR9ylKhB0S6EQHjGj7EoMzaqLx/sCw8+Pdg3axvGW4U72nvirgqd7MzBXJkZ5IcMxaItOmlc5La1uV4vrJ7cewz7jgzot2ysinQz4y3HeD1W5szlulzJkd3btfrt442r8MOvrQ0v8xCZAV0yvzBq21rxZCzkN0duHW5uqg6/ZvdRvHHyAsYmg1HjrsiZHq1PAXhfKXVaKXUZwIsA7nBgu55iLrI2NX6CA42j+SJHVkWL9rXrl5bipT/5DBqXLQZELBcA3NHeM+udpFG8ngjz8+uSfSeZQ+NvciZDThWv+lIfkSxoi08C4Sw8cUcDyosLsXTxArxx8oI+Ts/q0SqxaD1Wi+YXYHVt+axjN2fOA3IiR+kusaKdv/fOjUZ9fXVtub52mrY0iL5tbUyDYcD7viMD0VkytEu9F8dTHneVK2/o0uHEGK1rAPQbPj8DgBVERFdvAF/d+TbGg1dW+eaYLEuez5FxejRwZSyNcRXls4FxTIZmMKPC7yIXzS9Aa3P9rHE05unXRrFmFLXtOYbu/iE0Vpel1E0fb+xWls02y5kMGWcH7rx3TUq/O+PvvG33UXSfGUZxYR4aq8uwdWN0x8vda2tw99oa7Oro02cRlhcXxsyO1fIQVtkzjxG0O0OVOUqd+Xee7O/QPDN1ZCKIRQsKZ7Ut2uzTe57rwOY1NVi0YGDWOD7j39oYroHhycgjfAoSPnnCeNwjkyF09w8BSH+phyzLkc6JQmv22+roJ4mEXySyBcAWAKip8c86LK0vHmKRlRzP52hHew8C48FZFzrt40N9AT0rBXkCKBV1QTNPudYawVgDlM0N5qnzkXewFtOw44l3Ec2y55TlTIaMg813tPek9Lsz/s61XoTx4Ize42Rl35EBhGYUCvIEj6xfGfN1sy7CkyG92AfCE3m0245O9l4xR/al+vxSrZgemQxFjRs2bsP8KJ33zo3q2YnZLkTal+sqS/QnT8Q7JuNSI3Z7RbMsRzonCq0zAKoNny8D8JH5RUqpZwE8CwBNTU2ptfQ5aNve43j2l6cxY/iX1lWWsMiKzfM5Mi9SaiyGWpvr8eg/v4PLgQnki+AvN66KmullRWtUzBdDq3eHO9p7MDo1jfLiQstp2EB67wazbKZizmTIOBs01d+d+XeuPaMw3nZaGqr0tYte7uzXe6uMOWxpqMLIRFB/DFTtVcVRxT4A1y5izJF9yf4OjQXS3Wtr4i5QOjA0gdKiApwNjGM8OBO1Rp+5vdDao7olC1FalI+xy9P64rbxjslq8eZ0ZVmOdKJSfHc7awMiBQB6AHwBwFkABwHcrZQ6GutnmpqaVGdnp639ZrOu3gC+8t23or72wLoVvhr4LiJdSqmmFF7vuxxpy3ysq6sAAP3jZB7i3NUb0B/6OzYVwsnBMTQuW4xFCwr1VcCvq1yIrbffOKuoi9WYGY8nW94NppIjP2YoGcZb1uXFhfqikY3LFuPVh27FpqcOoPvMMEqL8vViPDAeHvwOAFBKL86z8bZMImyL0mNchqhuyUL94dDaG0BtWQitvbC6BdhYXTZrmQgAlss9ZLtUc2RkezC8UioE4CEA+wEcB/ByvEB63a6OPvxHU5H1P3//Jl8VWenwY46Mg1m1j1dVLcLNT7yGXR3RMwrNyzbsaO9Bd/8QFi0ovDIAOtKroT0sWHs8BpDcFOp0B9dmC69nKJnBwubX7Orow53f+5VeZO28d01UXox/L128IGqxUyilZ8z4pIBcKrLS4fUcmcXKVWtzffjJAdVl2PaVT+pLwzz6yrvh2YWXp6PaCy0fWzeu0h/3NDYVsty2tqZbvIdNe4kjC5YqpfYC2OvEtnLdX/3rEcwYPn9g3Yqcqdgzzes5ivWIG+PXtZ4HYxc9MHtMT6zB8dotKW079z9/UB9sbee5h7nCyxlKZvyJfjs5snjp4bPDmFbQx2btaO/Bp6+9Cr0fj+nT8s0LUQKxbyn5hZdzZBYrV6try7H19hv1mYPmZ2aWFBXorzdn5brKheECPnLr2Ti8YXVtOR5Zv1Lv0fIDrgzvkK7eAB5+8RCC01duxf7P37+JRRbpzA3aro4+PLn3OKZnZvRB8LEaIK2AattzbNYK4OaPzcWWNtg6WweKkjWrlfu1FeC158KZX9PSUIXDZ4cxdnlaf1hvQZ7giTsa9IHJWsGuPbMwVoHthcKbEjMOjjdPrjE+q/DcyBTqKkvwn29dgX1HBqJeHzVBA9BvKWrfG5kIRrU92mxYv2Ch5YBte4/jmTdOR31tU+MnfBUkSszYC2V+aK9xJqLxafdmvR+PJTVTzWqwtVMDRbN1CrXXWBXG5vNvfE1rc71+S6b26hLUVZbg3MgUHttwg/54JiD64dKJ8Fx7n1ZQG8dkaQWSNsP0UN8QRqdCKBgTvUjSXj8yGV5Nvq6yBCOTIb2n1LhWX7zeUT9kjIWWTV29gVlFlt8GvlNyjD0E9zzXgdCMQr4AVYvno6J0PoD4t4diLQ8BWDdW5h4Jp3oo2DM2N6xuD5vPv/Fv7fsFeYLNTdXYd2QAJwfHLHuukn0TqK3TNTIRjHqeHXmPOUtWve8VJfP03lTt9dqg+PLiQpwcHMOi+QWz2gU7S8R4oRBz5FmHfrXpqQNRswuLCgSv/JffZZFFlrp6A9j01AF89ts/Q8fpj1FcmI+2TTehYmERuvuHsPmZt7CqalHMAemtzfVorC4LT7s3sbN6e6orMuf6oHmnuL2StXYx01b1137vsRY4bWmoQr4gvITDwT60NFShtCgfpy+MYdPTbyZ1nLP+TTGeZ+fF1btzhVvnwDjZQcuadntQc3JwDG17jkUVP1tvvzFqEkVLQxU2Pf0mNj11ALs6+uIea7wHksd7dmKuYaFlQ/eZ4ajPd339MzlbcZP7tEeZ9AcmMDWtMB6cDj++InIRm1bAS539cWd29X48hu4zw7ManUTFT7zGOdUizS+zzxKZi0cTGWebApj1ezcew74jA9CHiIpg35EBjE5N40xgQn8cijkH8Z6FCUB/FIu24nwOPY7Js5x+U2X1Ne3/uDaub/v+E/oDp6FU1DEYe6sOnx3GP7z5Abr7h9B9Zhjb95+Ie6zmxztZ/TuhVM6/seOtwzRs23sc37MYk+X3Cw/F19pcj0N9AYxOTQMAigvz0NJQhZcP9mFJ6Tx8fOkyfq++MuZq71a3jsyLnsbqYo/3yBfz2LFc76afK3OxOKJxtmnb7qP6o1K0c9PaXI+RiaA+NmZgaAIfXhzHu/1D+HLjJ/S1sUqL8i1vCZnHeBmfhQnMvuWTrQtC+omdc2B1my7e7eFVVYvw1qmPcdM1i9H5YQCAwuY1V8b7GduMzg8DGA9OYyo4HV6DTYVfG288YLx/i5MLmWaa7QVL05HLi7tZLUbKx+rMZmdxt2TlYo60hUbHJoOACM4NT4YHmeaJ/hy6wHjQctFQqyJIG5DauGwxei+Ox/1ZbRZivAVJs23RUrdzlOkMJVPYaos7Viwswsnzl2adG6uFb4HwbMOX/uQzUc8uNA6EN89aND4L02qRyVzFtugKq7xtevpNdPcPoW7JQlQtnh/1vZufeE0f96dN3FlWvgAH/uLz+ja1/BUX5mE8OIO6JQvx+n//vbn/x7nMTo7Yo5Witt3R69axyKJUrK4tx6sP3hI1w0drxAryBHc2VePYwIjlOzyrAaX6gNTJUMyB8trPJvPIF/ZYzK1kJhbsOzKgzyS0uoViPmcfXBjDR0MTuP/Wa/XxNlYPMwdMmdLedGfgzTfNDas2RFtHzbwEA3BluZk7m6r1SV8DQxNRP29cHsKq94q95Cy0ktbVG8Aff79Dv+0DcHYhpaerN4CRyRCWlc3HxbEgrl44D0PjlzE6Na0XWVovxMsH+wARbN24Ku4io8k0ZlaNbKxFVMldxucLAvaeBWfOwHfuujnqdW27jyIwHkS+hG8FWd2a3tXRh1ODY6irLIn5LEzyJqs2xPjxocdvQ1dvAHsOD2BgaAJf/+yKmD+/78gAgOh8a0uOANHLRhh7Vr2OhVYSunoDuPvvf4Wp0JV3eq/8l9/1RUDIOVrjMzA8iZPnL6G0qADjwWmMB8IPbtXGxhjHU2kNVDLrZhm/n+y7SC7VkBmp/N61c7urow/3P38w5vPhYm1z7HL4zaE22SIwHpy1Urc22LlgTNiu+ZR5+RnzWL4zgQkU5Alqri6x/Hnt1rO2rlZ3/5C+/pbW027Vtvmh3WGhlYQd7T1RRVbjssVsjChl5kdYLF1UhOuKSnBqcAyjUyH9mXLGrnitRyvVW3nJXsh5qzAz0vm9G58PZ1Voxdpmybxw3kqL8vHI+pXYd2Rg1m0ivz0SheKzWqftrVMfIzSjYubP6tbz0kVFuLmsLOrpBkBqi+Z6AQutOMKLtB1DWfE8VC6ch4tjl/H1z/J2IaVOu13YuGxx1Ewc84BkIPqdZaKFJWP1XLGAym7p3KJNVAwZt2le58iYkeuXlqJtz7Go2YXGR6JwTA1Z9aI+cUdD3PxtXlOD3osn9FmJVhlKZ9FcL+A6WjHs6ujDN350GKNT0+gPTOCGqkU49eSXWGRRWna096C7fwiLFhTi7rU1lutQvXdudNZ6Nrs6+nDzE69hV0df1Gv1xfx2H7VcpybZta64LlJ2slrb6PqlpXEfz2Rktc6R8fl1What8hEvE9pxxVqIkguaeou5F/XQ47fh+qWlszLQ1RvQX/tyZ7/rhXqu5Yw9WjFs338i6nP2DJAd8XqY4o1biHW7SPuZxuoyW4v5secrO1nd+k1lXFey6xOl+rOJxthwzJ+3WPWiWmUAgD7rGUq5noFcyxkLLZNte4/j7395GqXzC1CYL5ieVtiybgW70MmWeLeKtAvaqqpFeKmzH6uqFmHTUwcwdnkaJfPyEZpWs7rrnVrMj7MMs5NxLIs2SzCVotg4E8w8yzDWLUbz961+NtEYGxbuuSferWKrXtR4GWhtrsd750bRe/GEPqPWyeMxH0Ou5MzWrUMR2S4iJ0TkXRH5kYiUOXVgmaA9IHpaAUMTIXxmxdU4vY23C93mtRwlS7uQAeF3ZccGRhAYD+Klzn50nxnGyfOXcGZoEtdVlswaz8DH4ETzWobMj0CxugWYjES3huN93/w94wUw1u3vdHOZLbeCvJajZKSSAeDKOTYWX8bzrq37pi314OTx5Cq7Y7ReB9CglPokgB4Aj9k/pMwxntiigtRnelHaPJWjZJkbFO15hY+sX4nGZYtRXBieLaY/2Jfi8WSGEj3D0u7Px/u++XtuXgCz6OLqyRzFk0oGjGKdM7czG2/fWUsp5cgfAL8P4IVkXrt69WqVTTo/vKjueOqAav5/fq6a/+YX6o7/95eq88OLmT6snAagU/ksR6nq/PCi+urOt2Nmzfz9RK9Pdz/ZLJ0c5WqG5vI8pbMvN4/PzW2zLXKWdq6e/LdjqvFb+9ULb/dm7Bjmsk1LN0dKKUdnHd4H4CcObm/OaAutnRwcQ9Xi+Xj1oVt5SyZzcjZHscS6LZLoNovVbLF03sXl3Ls/+3IyQ3N5nqxuCya6defm7eosvRWekzlym5YdbfFb42rwc3X7N0vzElPCwfAi0g5gqcW3vqmU+nHkNd8EEALwQpztbAGwBQBqarJs/YzIAmvaE6fOT6sAACAASURBVO7Jeb7IUQxOzZBJdwBorg0cjcXrGZrL82TeV67N4rLD6zlyW6zB8H7KUKpE2XyAqIjcC+ABAF9QSo0n8zPZ9qRzLtDnvFSfdO6FHMXCfKUvlRx5OUNu83JG2RbNDS9nCEg9R0a2lncQkRYAfwHg95INZDbiFPfM8kqOYmG+3Of1DLmNGQ1jjtLHDMVmd4zWUwBKAbwuIt0i8owDx0T+wxyRXcwQOYE5IsfZ6tFSSv2WUwcyF7zetZmrci1HTmMu7fN7hjTMkj3MkX3M4Gy+etahD2dfUQ5gLskpzBJlGjM4m68eweOV2VfkLcwlOYVZokxjBmfzVaHFwXqUjZhLcgqzRJnGDM7mq1uHRERERHOJhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRSxwptETkz0REiUiFE9sjf2KOyAnMEdnFDJGTbBdaIlIN4IsA+uwfDvkVc0ROYI7ILmaInOZEj9bfAfhzAMqBbZF/MUfkBOaI7GKGyFG2Ci0R+TKAs0qpdxw6HvIh5oicwByRXcwQuaEg0QtEpB3AUotvfRPANwDclsyORGQLgC0AUFNTk8IhkhcwR+QEJ3LEDPkb2yKaa6JUer2jInITgJ8CGI98aRmAjwB8Sil1Lt7PNjU1qc7OzrT2S7lBRLqUUk1JvI45opjczhEz5H1si8gJyebISsIerViUUocBLDEcxIcAmpRSF9LdJvkPc0ROYI7ILmaI3MJ1tIiIiIhcknaPlplSarlT2yL/Yo7ICcwR2cUMkVPYo0VERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5Je2V4WzsVGQXw3pzvGKgAkKnF5zK170zt93qlVKmbO/Bhjvy2X8DlHPkwQ5ncN9si5/ntXGZy32nnyLF1tFL0XrpL2dshIp2Z2G8m953J/c7BbnyVI7/tV9u3y7vwVYYyuW+2Rc7z27nM5L7t5Ii3DomIiIhcwkKLiIiIyCWZKrSe9dl+M7lvL+/Xy/827ndu9s3fKfebK/vgfjO777T3m5HB8ERERER+wFuHRERERC6Zk0JLRP5aRM6KSHfkz4YYr2sRkfdE5H0RedSB/W4XkRMi8q6I/EhEymK87kMRORw5trRnFiQ6fhEpEpGXIt/vEJHl6e7LtN1qEfm5iBwXkaMi0mrxms+JyLDhHDzu0L7j/u4k7H9F/s3visjvpLmfjGQosk3P5yiTGYps29M58kOGItv1fFsU2RZzBLZFSedIKeX6HwB/DeDPErwmH8ApACsAzAPwDoBVNvd7G4CCyMffBvDtGK/7EECFzX0lPH4A/xXAM5GP7wLwkkO/3yoAvxP5uBRAj8W+PwdgjwvnNu7vDsAGAD8BIAA+DaAjlzLklxxlMkN+yJEfMpTpHM1Vhpgjd3PkxbYom24dfgrA+0qp00qpywBeBHCHnQ0qpV5TSoUin74NYJnNY4wnmeO/A8DzkY//GcAXRETs7lgpNaCU+k3k41EAxwFcY3e7DrkDwA9V2NsAykSkyqV9OZ4hwB85yvIMATmeIz9kCMj6HM1lhgDmKC1ZniEgjRzNZaH1UKSb7fsiUm7x/WsA9Bs+PwNnf7n3IVyFWlEAXhORLhHZkub2kzl+/TWR/yzDAK5Oc3+WIl23NwPosPj2Z0TkHRH5iYjc6NAuE/3unDyvmc4Q4IMcZSBDgL9y5PkMAZ5viwDmKOo1bItic2xleBFpB7DU4lvfBPBdAG0I/wPaAPwNwiGJ2oTFzyacEhlvv0qpH0de800AIQAvxNjMLUqpj0RkCYDXReSEUuqNRPs2H4rF18zHn9a/MekDEFkI4BUADyulRkzf/g2AWqXUpch4glcB1Dmw20S/u6T/zZnKUKJ9+ylHGcoQ4IEcMUOGjed4WwQwR2Bb5EiOAAcLLaVUczKvE5G/B7DH4ltnAFQbPl8G4CO7+xWRewFsBPAFFbnBarGNjyJ/nxeRHyHcZZpqKJM5fu01Z0SkAMBiABdT3I8lESlEOJQvKKX+xfx9Y1CVUntF5H+LSIVSytYzo5L43SV9XjOVoWT27YccZSpDke3lfI6YoTAvtEWR7TBHbIts50jbqOt/AFQZPv5vAF60eE0BgNMArsWVgXc32txvC4BjACrjvKYEQKnh47cAtKSxr4THD+BBRA8cfNmh368A+CGA78R5zVJcWTftUwD6tM9t7Dfh7w7AlxA9cPDXuZQhv+QoUxnyS478kKFM5mguM8QcuZsjL7ZFtg4qhYP/RwCHAbwL4F+1kAL4BIC9htdtQHiGwSmEu0nt7vd9hO+ldkf+PGPeL8IzKt6J/DlqZ79Wxw/gCQBfjnw8H8D/iRzXrwGscOj3eyvCXZfvGv6tGwA8AOCByGseivz73kF4EOXvOrBfy9+dab8C4OnI7+QwgKZcypBfcpSpDPklR37IUCZzNJcZYo7YFqWaI64MT0REROSSbFregYiIiMhTWGgRERERuYSFFhEREZFLWGgRERERuYSFFhEREZFLWGgRERERuYSFFhEREZFLWGgRERERucSxZx2moqKiQi1fvjwTu6Y50tXVdUEpVenmPpgj73M7R8yQ97EtIifYyVFGCq3ly5ejs7MzE7umOSIivW7vgznyPrdzxAx5H9sicoKdHPHWIREREZFLWGgRERERuYSFFhEREZFLWGgRERERuYSFFhEREZFLWGgRERERucSxQktE8kXkkIjscWqb5D/MEdnFDJETmCNyipM9Wq0Ajju4PfIn5ojsYobICcwROcKRQktElgH4EoCdTmyP/Ik5IruYIXICc0ROcqpH6zsA/hzAjEPbI39ijsguZoicwByRY2wXWiKyEcB5pVRXgtdtEZFOEekcHBy0u1vyGOaI7GKGyAnMETnNiR6tWwB8WUQ+BPAigM+LyD+ZX6SUelYp1aSUaqqsdPX5npSbmCOyixkiJzBH5CjbhZZS6jGl1DKl1HIAdwH4mVLqj2wfGfkKc0R2MUPkBOaInMZ1tIiIiIhcUuDkxpRSvwDwCye3Sf7DHJFdzBA5gTkiJ7BHi4iIiMglLLSIiIiIXMJCi4iIiMglLLSIiIiIXMJCaw509QZwz3Md6OoNZPpQiBzFbGcezwFlE+ZxNhZac2BHew/eOHkBO9p7Mn0oRI5itjOP54CyCfM4GwutOdDaXI91dRVoba6P+zq+E6BcoWW1paEqqWyTe5JtX8zY3pATzDlKN49exkLLIfEardW15fjh19ZidW153G3wnQDlgq7eAO5//iDeOHkB+44MJJVtck+y7YtZMu0NizFKxJyjVPPoh4w5umCpn2lhA4Affm1tWtvQ3gHwnQBlsx3tPQiMB1FeXMis5rBk2hsn2jXyNrvXLT9kjIWWQ5wokrR3AkTZzJh19mTlrmTaG775o0TsXrf8kDEWWg5hkUR+waz7B881uc0PGeMYrTnkh3vR5D3Mbe7jOaS5xLxFY6E1h1IZ7M6gUjYwDnznJI3cYW4/ONGGnBbvGsW8RWOhNYfiTXtlw0jZRiuyOPA995jbj9bmejRWl2FkIsg3b+SItj3H8MbJC2jbc2zW97jEQzTbhZaIVIvIz0XkuIgcFZFWJw7Mi+JNe7VqGP0UVOYo+xhnF+68d03WD3xnhq4wtx+ra8uxaH4Bus8M881bAsxRkpSK/tsg3SVHvMqJwfAhAH+qlPqNiJQC6BKR15VSs8tcisk888IPAwRNmKMsk4OzC5mhCKv2ww+zuxzCHCVh6+03Ykd7D/OUBNs9WkqpAaXUbyIfjwI4DuAau9vNZm6Mn/L7OwA/5igbGbOda5lkhuJLdD45LjSMOUqOOU/MT2yOjtESkeUAbgbQ4eR2s02y46cSBY/BtOaXHGWbXR19uPN7v/LE2EBmKHlaO9S2+2ja596rbRlzlDztuti2+2hKWfBqdowcK7REZCGAVwA8rJQasfj+FhHpFJHOwcFBp3abEcmOn0pUkHHA+2x+ylG22b7/BEIzCgV5ktO3A5ih1Ogrc4ukPS7Ui20Zc5Qa7boIkZSy4MXszKKUsv0HQCGA/QD+ezKvX716tfKKzg8vqq/ufFt1fngxpe8l8/1cBqBTMUc5Qcvhk/92TDV+a7964e3eTB+SLtUcMUOpS6UdivXabG7L2BbNrVSzkCuZSidH2h8nZh0KgOcAHFdK/a3d7WUbrVtzV0efZfdmvGo81pgIbZsAZn3fD92oVryeo2zU1RvAZ7/9M3zlu2/hjZMXcGxgBIcevw13r63J9KGlhRmKtqujDzc/8Rp2dfTpX+vqDWDT029i01MH9DYmlbF4sdq7XBvPFw9zlBzztcp4XWttrseO9p6Y102jWNnxUk+XE7MObwHwVQCHRaQ78rVvKKX2OrDtjNNO9uGzwwiMBwFEP/gynZk88R6i6YcHbMbg6Rxlox3tPegPTOif5/LtwghmyGD7/hMIjAexff8JvXje0d6D7v4h/eNU2xifzFxkjpJgvlYZPwcQ97qZDC9lzXahpZQ6AEAcOJaspJ3kloYq7DsyMOukp7MMQ7wAtTbXY2QypC8saJzRoU2l9cK7RjOv5yibdPUG0LbnGMYmg1hSWoSPL03h659dkfO5YoaiPbJ+JbbvP4FH1q/Uv9bSUIVDfUNYuqjIExcwNzBH8WnXopaGKgCzr2fGXMW6bpq3ZXVd89ISR3yodALGk+3ULZV4AdIWFtS6TLXXGXvWcmHxSMpebXuO6b0a6+oq8MOvNWf4iMgNd6+tmdVm7TsygNGpEG4uKwMA3PNcR0pv3nzc4+57WlE0MhnS2w9jBszXtWSum37JEx/BM8eM97VjjceymtXY2lyP0qICBMaDlo88IEqkqzeAL/7tv+PdSCNZWpTPXg2PM7cxxrbFOB3fPG4rFr89sSJX2R3ra/XzelGkVMoZSOVa50Xs0UqDsetU6xaNd4uvqzeAtt1HARFAKXSfGQYA/Z3ByGQIrz54i759qx6v1bXluK6yJPyzFo88IIqnqzeAO7/3K4RmwtkpyBP84D5vDF72O2ObAyCq/dEujiMT4XEyY5enAQBtu49i85pwT4OxhyLRuC0v3c7xMrs9Reaf7+oNYGB4EqVF+di8ZnZPKWB9XdS2NTA8iZPnLyV1rfMiFloRqYyBijdA3iqg2oN5AaCxukyv4Nt2Hw1vMMnCiY88oHR09Qbwx9//tV5kAcATdzSwyMoy6Y7DtBqEDITbH62tMBZTmkULBvQ2qm3PMUCpWW2L18eGepXdgeTmn2/bcwwnz18CALx8sG9WBwNgfV0EwnksLcoPf+LTTgIWWhGpvAOIN0DeHFDtwbylRfm4bkkptm5cpYdz85oa9F48ob+zTMQv1T85q233UYxOhfTP19VV5OwSDl6Wbi+E1UXV/MxUrVdd69EqmZcf9RpjLwNgGI8zEdR74Nn25A6714pZPx8pkEqL8vUFSQHrGfhW18VVVYvwUmd/0tc6r+EYrYhU7hVrIbx7bU3CtWO07f7gvrXYunEVdrT36Pep9x0Z0Kdfp3Iv3a9rbVFqunoDuPXbP9MvlKVF+Xjlv/wuL5hZKt3xKqtry/UxV++dG436nnFto62334iqxfOx7SufxKsP3Rq33XJitXjKDclcT7befqN+HdvcVI3y4kJ91mE82rXy2MAIAuNB7Dsy4OSh5wz2aEUkegeQbBe6eXag1feAK936WjdrKmva+GWmBqVv297jeOaN01Ff45is7JaoDdrV0acv12DukYw1nMHYVmi9UyMTQbz60K1xj8XYS8bMeFvb7qNJ5WJkMqSPNdaKJmMO4w2p8dKaWOlgoZWkZIsbY/F0//MHUXtVsd6jYA7b6tpy7Lx3TcrjrvweWoqvqzcQVWTlCzyxTpbfWS1Aqol126a1uR4jE0GMTIb024aQxEtEcZiCj2h5iJML40K3dZUllj1a8W4d+j1PvHWYpGS79bXiqbQoH4HxIMYuT+s/Z+zit3r8RbK3BL30uAty1q6OPmx+5i398wfWrcCpJ7+ERzfckMGjIic8sn4lyosLoxYg1cQbztB7cRzd/UMoKSrAuroKbN24ynL7iR43Rt60deOquLkAwsVTaVEB6ipLUDK/EIHxIF7u7I/KiTGD5uuc37FHK0nmijzRirbXVS5E95lhlMzLj/o5q1uL2nZ4S5Ds2NXRh2/86LD+eeOyxSywPMRqAVIrxrZJm4xTXlyoX0hjtVuJHjfGGYjeFK+3ybhIqbbQrZarkYmg5fXKPNOeGWKhlbZERVGspRjM47K0cRMDw5MomZePxuoy3hKklHX1BrD11StFVnFhHrbefmMGj4gyxdg2mcda3fNcR8x2S3v819hkELVXl6CloSpq5Xi+EfSOVMccNy5bHHVnRpvJanWNMxb3Vt/T1nVbtKDQNwUXbx2moas3gJHJEBqXLdYbI6suUm3woPF72q1F/TZk5L74ueEJdJ8ZxqL5Bb4IHjlnV0cf/uN338J0ZIma4sJ8/OP9n2aOfMo4zMHYW3HPcx1oaahCY3WZ/ixVI+3xXycHx7BofgFe7uzHGycv4I+//2t09QZ8s4q3H2gFz472nriv08751ttvTPp2oPYzVo+K0743dnk6/FSCJJ5y4oVZ9iy04oh1grWBgYsWFGLfkQHLwGqv6T4zPOt7xjFW2v3xxzasYiNGKevqDeDxHx/BTOTzfAH+8X6O3/Mzq7Gg2oV135EBLJpfYNkuAaaxqJG1k0anQtjR3sOxoR6STtFsLs5iFWvxcqJ9r2Re8guYJlsUZjPeOowjVle51sU+MhHUF2CzukWodcOPTIbQ1RuIGzzAuYdWkz+EV3zvQGhGQQAsKMzHXxoWxCV/shojE29RUyNje7T19hv16fytzfW+HV/jRcnOAjQu/aANRTBnSfs7lXyk8pQTL8yyZ6EVg/H2oPkEa13sb5y8oD/GwkxbbVkbE5HsOllszCgZWpE1OhWesv/b1WWzVvcmfzKPkbFqU5Jpi1bXlketqxRvfJeG7ZfHGJZ+SFScmccGxstBKss9eGFpCEduHYpIi4i8JyLvi8ijTmwz04y3B62CEq/r1XjL0fi6rt4ANj39JjY9dSDm/WYvdJOmy4s5coO2hINWZJUW5cedmu0nzNDsMTLGNsVqOESyY2CSafPa9hzzRPvFHIXFW/qhbffR8DiryDN7Wxqq9PW1tBwkMwbLD2wXWiKSD+BpAP8BwCoA/0lEcr7VT3QP2zzI1NhIGRs24/1q47ittt1H9Z+LVZgZeWFAYDxezZHTtCUctIHvpUUFXPE9ghkKsxoAv66uAi0NVbj/+YOzCiHzBdNKop4qvTdDqZwfa8ocXRFvvNXHY5ej/tYeKbfvyADGIs9WHTM8Y9WK169rGiduHX4KwPtKqdMAICIvArgDQM6UslaNSDLdlcaxEIfPDuOR9Sux78iAvmJurHFbUCrqwZwAorrkrfbrg6nVOZ8jt5kfq5MH4Af3fYpF1hW+zpD24GiI6M9VNbYZ9zzXod9S1GZLtzRU4dTgpfAGEqwMHq/98dgje3ydIytW18iPL12O+ntV1SK8depjrKpahJGJ8PhAfdB7DD64rgFwptC6BkC/4fMzAHLqN5buydbGQhTkif5ojMB4MBwyEbTtPoqtt98Y1fAsml+gN0rmwYDx3gV6YUBgAjmfIzft6uibVWT9j9+/yQsXNSf5OkM72nv0x31pbYv2+B2ttxwI3+LR2qrDZ4cxOjUdtaCpWVdvACMTwbhr/HlhHI2Br3NkpW3PMXT3D2FkMqQX8VeVFGJ8aBrXlM0HALzU2Y/QjMJLnf0JHy2nFW6xOiW8xolCy+pt0Kw5myKyBcAWAKipya7ZdekWMeZnO2l/j0yG9OdCGQfBmws6Y8OUqJHyWENmJedz5Kbt+0/oHxcV5GHX17lOlgVfZ0grrLRZgqtry7FoQWHUZBxzz5bWCx+vJ0or4NbVVfglc77OkSVtGQalrixiWl2GFZUL9evgI+tX6g89T2XgvMevawCcKbTOAKg2fL4MwEfmFymlngXwLAA0NTUlXjxjDlmFoqs3EB7Ip5TeK2XuPrVamuHutTVRP2vVY5VKQWe+HeDhhi7nc+QGbaZXXWUJQtMzWLp4AbZ95ZNezoEdvs+QebVt41I02hIz5tt8sZaVsep1MH4tUYGWw3yfI/N53rymBosWDMy6nhnP/fVLS3HTNYsBIOqJAlbs3qHJtdmtThRaBwHUici1AM4CuAvA3Q5sd84ZCySIzOqVMnafxptKry3tYNyuFopUq3fj7YC23Uejplt7jGdy5BTjdPqTg2P4cNuXMnxEWS9nMuTGhcKql8C4FI3VEjPxjsNqe1omYz0PMV27Ovr03pAsWE8wZ3LkFm39rEN9AX12s3HJhnjjiA/1DWF0KhT3OmnspEjn/0Ky1+JsYbvQUkqFROQhAPsB5AP4vlIq9vSVLKbNCgSAusoSNFaXRfdKGbpPU92uscFKJVitzfVXwh4ZrJpr1XwyvJQjJ2zbezxqssS6uooMHk1uyKUMuXHrxKqXwGo9QOO+gfBEnJHJkD5+1Ngbpv1t7t0y9mg5QRsztn3/iYwXWrmUIycZi13tWlNWPA8F+SG0NFQlPSFiYGgCo4OhpK+Taf1fSPNanCmOLFiqlNoLYK8T28qkcFETrsbPjUziB3/w21GFzOY1Nei9eEJfDT6V7RoHpcYK1q6OPjy59xiWLl6AL6xcgpc6+/HI+pX4wX1r9cKqqzeAr+58G+PBGQwMTeD1P/2cI//2bOCVHNnV+K39GJq4Mi16XV2FL8YxOCFXMpTsrZNU3lRZDYHQ3jw2Vpfh0VfexdnABK4qKURjdRlaGqrw8sE+/Q1lvDeDm55+E939QzjUF8BjG1bpY1KdesNnHN+TDXIlR5pkchLrtq/29c4PL2I8OINv7T6Cefl5qFuyECXz8tEfmMDLneG5Acbn+5q3k+hh07EYxzonuuWoSWVl+WwgKgMVYVNTk+rs7Jzz/SbDuGSD+QKndZvHu/BZdYEbt6k1amOXp1EyLx/LK0qw590BbPxkFfa8O4DQTPT5KC8uxKHHb5u1HSC8htLhb61349dgm4h0KaWa3NxHNucoXQ2P78Oly9P658vKF+DAX3w+g0eUWW7nKNszlKjNMV88zRc/rT2qKJmHk4Nj+s/VVZbg9IUxTCugsbpMn0mm/Zy233wBVlQuBACcPB9eBqK0qACjUyGUFxdatpPZxqttkbGg0d68W50L7XUjE0F0nxnWz1t5cSF23rtGvw1XVJCHqdCM/nPhNfo+FfWzBXmCa68uxsnBMZQW5WN0ahp1lSWoKltgWSCl8kYhmetrJtnJER/BY6H26hLUXqVmVdixKm9jmMxd4OEeqA6MB6dRXJgPKKWPuQKgf/xqd3ispSB6ekthfh42PXUAW2+/EY++8i4C40Hk54Vf9IemLnarAfyUO5Y/+m9Rn+cLsOOumzN0NJRJyQ5E1y6wWm/Um+9fwLQCDvUFUFY8Dx8NTWBaASMT4Qvr8HgQV5fOw6kLY9De0/WcGwVwpSfrnuc6cFXJPADAtAoXWHWVJSguzMN4cAaLFxTg5pqyqOIu2Z4Ico527rU1HI13TYznQSuk6pYs1Beu1a5Td37vVyjMD98mnArNoChfMBVZDflyaBrvRbKxeU0NDp89jNCMwvuRImtx8TyMTk2g7+IETg6OWd5hMT4r0Ti+2NzrZb4tnW6esnVYDQstE62rfV1dBfYdGYjqTteKLa1X6VBfAEsXL8C54Ql9wKDWBX5nUzXuea4DI5MhjAfD38vPC3d53vm9XyE0o1CQJxABgtNXSquFkXcJmvOjUzg/OoVHX3kXp7WFBVW4ATw2MGJ57NrH2fiugKzduu2ns7526kkOfverZAeitzbX461TH+s94VpTMjo1jdGpCX170woYHg9iBkBoWsHYcT4enMb9zx/U2y5tbUCjkvmFqF9aiO7+IVSUzo+abZ3MMxDJea3N9XoW9h0ZmLWUhy5y16pkXr7+9euXlurXIeNdlKDh46lphcd/fET//orKhTh5/hIUwvlaujgf5cWFuBRZ/f3s0OSsYxyL9M73/H+jUQWglu+RiSB6L45HTaywk6dsXTbCV4VWMtWucezEe+dGcfjsMFoaqvSfHRieDPcqSaQxi3Sn50u4EtemuL59+mN0nxlG47LFqFuyEGcD41i6eAEA4Ik7GqLGI3xr91EEQzPYsm4Fzo1M6r1bRfmC/DzBeHAGpwcvYVoBBXmC+2+9FscGRuKuPJ8r964JuOEvf4IJQ5c9EL61Q/5lNYarpaEKh88O486m6qj//9deXYyzQ5O4auE8DI5OYioUvjAW5kvUmziF8G3CzU3V+Ic3P9DHaw1PhBAYD+LJvccwOjWN0qJ8/OHaWvz9L09jWgHFhXmAUlheUYIjZ4fx6WuvSnis5L7VteWWC4Oaz4PVeKbVteW4/9ZrsfPAByjMF0wEw+1PYZ6g5upw26N1IGgPJ3/96DmcHryE0vkFmJ4BoBQC40EUF+YhOK0wGZrGro4+AMCTe49j6aIivV0bD85EFYDasYxMhvTC3rx4aTp5ytYs+mqMVqr3gI2vB6CPWZhWwLKy+RieCOLytNLvazdWl6H34zF9LJZxFk8y++7qDejvMrTtbd24Su9B0+6pZ1OXaCxeHRfhtIdfPKQX1kA4Vwce/UIGjyi7+H2MlpE2IL20KF9/vqW5Xbnpr/ZhdGoa+QLctKxM7+HWaK8z/lxrcz0e/ed39NuJjdVlePXBW66M7YkswFyQJwjNqKhxo7mAbZE1fY2+JQtxbngSk8EQgjPhN3mv/+nnZnVM3PzEa3pRFJpR+jWupaFK7/kqLy4EAL2HSrvdXFyYh3+8f/Yiy/HGRGcbOzmygHEGkgAAIABJREFU/VDpXJLoQdFA9EMuja9vba5HaVGB/g5veCKE0alp3LC0FI3VZairLEHPuREExoMoLcrH5qbqqO0ms+8d7T0IzSjkIbyPzU3V+ruWdXUVOVNkUXK++De/iCqyFhTkscgindYW7erowz3PdWBsMnzxGp2a1h8K3dJQpT+7EAAe27AK5cWFaNt0EzY3VaO0KB/V5QuwrHwBSovyo3oNtPZodW05Loxdxkykx1x7FI82i2zrxlVYV1eBjZ+sQkGe4E5T20a5ScsAAIxOhfTbzudGpgBAHyqzo70Huzr6UFJUgHwBNn4y/JDyT197FQ6fDY8xfuKOBv1JA4+sX4nSogLUVZbgmvJiAED90kX6eGbjQ6SN17ds64Vykq96tJIRr+dp01MH0H1mGMWF+RgPTqOoIA/z8gV/uLYWL3X261W8VumnOoPCPEMo2yv8ePguMrau3gAe+KdODI5e1r+2qfET+A4Hvs/i9R6teMMZjGNVgHC7AiBqsksy7VWpYdxnrDZFa3uMtyVjHU+utUtsi+LTclK5cB4C40Hcf+u1+OKNS7GjvQenL4zhTGBCv+YB0Isi7e5LvB5Oc75zNUMAZx06Ktaifzvae/DpFVej9+I4SublY3xoGpdDM5gKAc/+8jRmVHg67HWVJVEPZ02lSt93ZACB8SBqry7xfIXvZ+Yiq66yhEWWT8UbvGsc6K71NJmLH6tFRfUiKbLo5OVpheLCfFxTviBmm2IeWxrreIx/kzdo60OWFc/D4KXLODYwgmMDI/pQmTAVucU4oa+fpuVSG2ts9abBvLZbOmtmeQELLZNYi/4ZZ/vUXl2CFZUL9anUAkQVRlaPKUh1IL4fwuc3Xb0BtL54iD1ZZLl8g9nq2nI8cUeDvohxIsairbW5HlAqqjeravH8uA+O1h4UHOtNng8ebO95VksA6W/wryqede6vKpmHPe8O4LYbl+LfewYxOjUd9UQA47UqmRl/Wob8NlOVhVYcxsZwZCKIscvTqL26RH9nef1f/gTToRkU5OfNmoINXAmQeaHRWI/hYUPmXV29Adz17K+iZoGxyMptdtbsMb55izf28u61NfoyM227j856aPSs4gpXnknXfWZYXyAZInF7Ecy9Vdm4FhGF2c2deQkgbTbr5jU1uH5paVRHwaan30RoRuGnx89jdCqkzw60ulal0uPpt95RFlpxGBuxRQsK0X1mGOvqKvRw15QvwMnBMdSUX3m3aRWgHe09+qxBq+eNsbjyvh3tPVFF1gPrVuDRDTdk8IjILjv/h41rICVa8844Fd68P3PPQqyvA9ZvAjXGn/Vbb0OusZs78xJAWo/WviMDs9aO1NbgWrqoCAVjor/O6nmUqXQU+K1TgYUWYr9DsCqajB9v+4PftlyfJF6lb/XAVvI27cG+2qMvNjV+gkWWB9j5PxxrDaRYr431DLlYF6xUexyM22bblN3s5u7VB29JuD3tY/MaXPHymq2rsmcDzjpE7s6myWac6XMF85U+r886zBZezijbornh5QwBnHVoG9/BkZuYL8p2zCjZxQzFxkIL/rtfTHOL+aJsx4ySXcxQbLZWhheR7SJyQkTeFZEfiUiZUwdG/sEckV3MEDmBOSI32H0Ez+sAGpRSnwTQA+Ax+4dEPsQckV3MEDmBOSLH2Sq0lFKvKaVCkU/fBrDM/iGR3zBHZBczRE5gjsgNTj5U+j4AP3Fwe+RPzBHZxQyRE5gjckTCwfAi0g5gqcW3vqmU+nHkNd8EEALwQpztbAGwBQBqamYvdkbexhyRXcwQOYE5ormWsNBSSjXH+76I3AtgI4AvqDiLcimlngXwLBBecyTF46QcxxyRXcwQOYE5orlma3kHEWkB8BcAfk8pNe7MIZHfMEdkFzNETmCOyA12x2g9BaAUwOsi0i0izzhwTOQ/zBHZxQyRE5gjcpytHi2l1G85dSDkX8wR2cUMkROYI3KDk7MOiYiIiMiAhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRS1hoEREREbmEhRYRERGRSxwptETkz0REiUiFE9sjf2KOyAnMEdnFDJGTbBdaIlIN4IsA+uwfDvkVc0ROYI7ILmaInOZEj9bfAfhzAMqBbZF/MUfkBOaI7GKGyFG2Ci0R+TKAs0qpdxw6HvIh5oicwByRXcwQuaEg0QtEpB3AUotvfRPANwDclsyORGQLgC0AUFNTk8IhkhcwR+QEJ3LEDPkb2yKaa6JUer2jInITgJ8CGI98aRmAjwB8Sil1Lt7PNjU1qc7OzrT2S7lBRLqUUk1JvI45opjczhEz5H1si8gJyebISsIerViUUocBLDEcxIcAmpRSF9LdJvkPc0ROYI7ILmaI3MJ1tIiIiIhcknaPlplSarlT2yL/Yo7ICcwR2cUMkVPYo0VERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkEhZaRERERC5hoUVERETkkrQfwWNrpyKjAN6b8x0DFQAytcpvpvadqf1er5QqdXMHPsyR3/YLuJwjH2Yok/tmW+Q8v53LTO477Rw5tmBpit5L95lBdohIZyb2m8l9Z3K/c7AbX+XIb/vV9u3yLnyVoUzum22R8/x2LjO5bzs54q1DIiIiIpew0CIiIiJySaYKrWd9tt9M7tvL+/Xyv437nZt983fK/ebKPrjfzO477f1mZDA8ERERkR/w1iERERGRS+ak0BKRvxaRsyLSHfmzIcbrWkTkPRF5X0QedWC/20XkhIi8KyI/EpGyGK/7UEQOR44t7ZkFiY5fRIpE5KXI9ztEZHm6+zJtt1pEfi4ix0XkqIi0WrzmcyIybDgHjzu077i/Own7X5F/87si8jtp7icjGYps0/M5ymSGItv2dI78kKHIdj3fFkW2xRyBbVHSOVJKuf4HwF8D+LMEr8kHcArACgDzALwDYJXN/d4GoCDy8bcBfDvG6z4EUGFzXwmPH8B/BfBM5OO7ALzk0O+3CsDvRD4uBdBjse/PAdjjwrmN+7sDsAHATwAIgE8D6MilDPklR5nMkB9y5IcMZTpHc5Uh5sjdHHmxLcqmW4efAvC+Uuq0UuoygBcB3GFng0qp15RSocinbwNYZvMY40nm+O8A8Hzk438G8AUREbs7VkoNKKV+E/l4FMBxANfY3a5D7gDwQxX2NoAyEalyaV+OZwjwR46yPENAjufIDxkCsj5Hc5khgDlKS5ZnCEgjR3NZaD0U6Wb7voiUW3z/GgD9hs/PwNlf7n0IV6FWFIDXRKRLRLakuf1kjl9/TeQ/yzCAq9Pcn6VI1+3NADosvv0ZEXlHRH4iIjc6tMtEvzsnz2umMwT4IEcZyBDgrxx5PkOA59sigDmKeg3botgcWxleRNoBLLX41jcBfBdAG8L/gDYAf4NwSKI2YfGzCadExtuvUurHkdd8E0AIwAsxNnOLUuojEVkC4HUROaGUeiPRvs2HYvE18/Gn9W9M+gBEFgJ4BcDDSqkR07d/A6BWKXUpMp7gVQB1Duw20e8u6X9zpjKUaN9+ylGGMgR4IEfMkGHjOd4WAcwR2BY5kiPAwUJLKdWczOtE5O8B7LH41hkA1YbPlwH4yO5+ReReABsBfEFFbrBabOOjyN/nReRHCHeZphrKZI5fe80ZESkAsBjAxRT3Y0lEChEO5QtKqX8xf98YVKXUXhH53yJSoZSy9cyoJH53SZ/XTGUomX37IUeZylBkezmfI2YozAttUWQ7zBHbIts50jbq+h8AVYaP/xuAFy1eUwDgNIBrcWXg3Y0299sC4BiAyjivKQFQavj4LQAtaewr4fEDeBDRAwdfduj3KwB+COA7cV6zFFfWTfsUgD7tcxv7Tfi7A/AlRA8c/HUuZcgvOcpUhvySIz9kKJM5mssMMUfu5siLbZGtg0rh4P8RwGEA7wL4Vy2kAD4BYK/hdRsQnmFwCuFuUrv7fR/he6ndkT/PmPeL8IyKdyJ/jtrZr9XxA3gCwJcjH88H8H8ix/VrACsc+v3einDX5buGf+sGAA8AeCDymoci/753EB5E+bsO7Nfyd2farwB4OvI7OQygKZcy5JccZSpDfsmRHzKUyRzNZYaYI7ZFqeaIK8MTERERuSSblncgIiIi8hQWWkREREQuYaFFRERE5BIWWkREREQuYaFFRERE5BIWWkREREQuYaFFRERE5BIWWkREREQucexZh6moqKhQy5cvz8SuaY50dXVdUEpVurkP5sj73M4RM+R9bIvICXZylJFCa/ny5ejs7MzErmmOiEiv2/tgjrzP7RwxQ97HtoicYCdHvHVIRERE5BIWWkREREQuYaFFRERE5BIWWkREREQuYaFFRERE5BIWWkREREQucazQEpF8ETkkInuc2ib5D3NEdjFD5ATmiJziZI9WK4DjDm6P/Ik5IruYIXICc0SOcKTQEpFlAL4EYKcT2yN/Yo7ILmaInMAckZOc6tH6DoA/BzDj0PbIn5gjsosZIicwR+QY24WWiGwEcF4p1ZXgdVtEpFNEOgcHB+3uljyGOSK7mCFyAnNETnOiR+sWAF8WkQ8BvAjg8yLyT+YXKaWeVUo1KaWaKitdfb4n5SbmiOxihsgJzBE5ynahpZR6TCm1TCm1HMBdAH6mlPoj20dGvsIckV3MEDmBOSKncR0tIiIiIpcUOLkxpdQvAPzCyW2S/zBHZBczRE5gjsgJ7NEiIiIicgkLLSIiIiKXsNAiIiIicgkLLSIiIiKXsNAy6OoN4J7nOtDVG8iJ7ZK37erow81PvIZdHX2ZPhQiVzHr/pXO9THXrqkstAx2tPfgjZMXsKO9Jye2S962ff8JBMaD2L7/RKYPhchVzLp/pXN9zLVrqqPLO+S61ub6qL+zfbvkbY+sX4nt+0/gkfUrM30oRK5i1v0rnetjrl1TRSk15zttampSnZ2dc75fmjsi0qWUanJzH8yR97mdI2bI+9gWkRPs5Ii3DomIiIhcwkKLiIiIyCUstIiIiIhcwkKLiIiIyCUstIiIiIhcwkKLiIiIyCW2Cy0RqRaRn4vIcRE5KiKtThwY+QtzRHYxQ+QE5oic5sSCpSEAf6qU+o2IlALoEpHXlVLHHNg2+QdzRHYxQ+QE5ogcZbtHSyk1oJT6TeTjUQDHAVxjd7vkL8wR2cUMkROYI3Kao2O0RGQ5gJsBdDi53UzItYdWeomXcuQW5jM+ZigzvJZL5ig2r51rNzlWaInIQgCvAHhYKTVi8f0tItIpIp2Dg4NO7dY1ufbQSq/wWo7cwnzGxgxljpdyyRzF56Vz7TZHCi0RKUQ4kC8opf7F6jVKqWeVUk1KqabKykonduuq1uZ6rKurcPyhlXwXEJsXc+SGrt4ARiaCaKwuy5mHqs4VZigztHatpaHKlXZzrjFHiZmvkby2xebErEMB8ByA40qpv7V/SNlhdW05fvi1tVhdW+7odrV3Afc/fxC7OvoYzAiv5igVyTZUO9p70H1mGIvmFziaz1xvKJmhzOjqDeCPv9+BN05ewMsH+1xpN+eSX3Jk9/+7+RqZbg9Xrrc7yXCiR+sWAF8F8HkR6Y782eDAdj2ptbke5cWFCIwHsX3/CXa9XuH7HCXbULnV2+qBWwG+z1Am7GjvwejUdPgTkcwejDN8kSOn/7+n2y55oN1JyPbyDkqpAwA88b9rLqyuLcfOe9dgR3sPWhqqsO/IgGUwu3oD2NHeg9bm+px+d5gs5gh6DloaqnDPcx0xz732TtKt/efqbR9maG5pbVRLQxVGJoKACLZuXJXpw7LNLzlK9/97rGtTuu1Srrc7yXBiHS1PcrPQMQby7rU1lq/RqnwArlxUKftoubjnuQ793Lc2189Zwe1WAUfe09UbwP3PH0RgPAgAePWhWzN8RJSqdP+/O31tSuc4cq0jgo/gicHp7sxU70O7dXuIsl9LQxXKiwvR0lDli251yi3GIqu8uJBtlM9kw0SxXGsXWWjF0Npcj8bqMoxMBOOe+FQGMKcSDPNAQz8MGKSwfUcGEBgPYt+RgaiiyynmLDFblKxte4/jK999Sy+ydt67Jid6FMg5iSaKpdKeGF9rvkbG206udUTw1qGJsUty0fwC/cTH6tpM1I1qHMcAzL4Pbfz+viMDWFW1CC919uOR9Sujbitq+xmZDAFK6eMh2MjlLu3ca+f8zqZqvP3BRYxNBlG3ZCFGJoJ4ubNfL7rMt5nN3efJdqebM8vb1JSMW7f9FGeGJvXPWWR5U6J2xNxuadcq7esjE0F0nxkGMHvog3nbWttz+OwwHlm/Uv8ZIP61NdeGObDQMjGe3GQG6SV6jVVYjGHTvv/WqY8RmlF48/0LmFbAk3uPRV1Yte0bQxyvAKTsZz73Ow98gNCMAgDkCzCtgLr/v713D67qOtO8n4UkBBK62YKRYl2wHWEsiCMaEZLYTVITbPQRHJNKymSciZ1KHI974ioy002PHTee/kxPTBfVPWHK7jgenG67v1DG0544bULApqc7HuxYQQoyF4HBFyQBogFzdEE3zpHW98c5a7PO1j7XvbfO2Xs/vyqVzmWftZbOfrT2u9/1rvedXzrtzs1qQsvEYDJrNgjBqMQeW/ccjzOyHl51E40sn6Hmlf6BMZy6OIKhsbBl7J153tq27wTuW9lgvN5SX2nMWalu6tqW1uLtDz42bib1ectP8xINLRP6yU3Hak51jN6ecYEcj6Crb8B4/cjZQcMVP6+4EH2hMUxORYWvJjPVT2dPCFteOwYI4QsBBhl1/q4rnY3dh/ux7rZanP54FB9cGDa2y5fOKTLOu9qJaDWh6e2l0oVZs167OyQzy872Xjz75ofG87rKOXh07a05HBFxAzWvlBXHzAItVYfuHFDzi+7RAqZfO82vWf3ee7QfkSmJwlliWniEn+YlGlomMj255qW/ZMs2xgWyrsK4QL53fhiRySk0LZiHrV+7DQCMQFMrj9Xyxiru8PEJ+i7DyJTE6UsjgBCoKZ+DGiFQWlxobJdP5GnVY/jScfc7sUvHazt+SPboO2CBqCeLRpY/0dPLmNMObXntGLrODOJQbwh/952VxnVJ10I2jomNqxfhUG8IwxOTePlgr+UufD/MNzS0TGR6UvU1ZrXVWXkgrNar9d/b959E+0eXMRGZwmRozOhv05rF2LbvBNqW1vpCZCQ5G1cvwtB4BCfPD2E0PAUAaFowD69+//a40ibqWPNkpe8CO3J20DJ2xsk4LMZ0BYM7/+pfcOriiPH8R1/9VMJ0NMS76NcY9f98S01Z/HUn5t0anpg0HAA723uxbd+JafHEOonmCv2zNy8oi67wxPpIFMdlbsNLcNehiUx3B6rdD5vWLI5bxlHtjFydNHaN6bs11PsTkalYS9Jo8+WDvQiNhvHUnm5see2Yp7axksxZ3liF8jmFhpEFAB9evBK3E0fFL1gZ29v3n0RoNIzCWcLwhOp09oQwNB5BS12FI8vNXtvxQzLnBy8dijOyVjVV08jyCebdfFa7/R584WDca5vXNaOlriKuvuq2fSeMCieJUHOFSsKs+tQ/u3ldM1Y1VU/z3qu+M5lv8nUHNQ0tE/pJTeekKePpvpUNcRdCtS0fUhqBfuZ+qkqKAACFswT+bN2Sa29qdw8Qghc1H5BKSxtXL0KBlot6UsK4q0t1/tUxT96zFC11FRgaj8T1s33/SXT1DaB8bpEjXlG36oCS/GBney9e7TpnPG+aX+pZTwKZTipDRt24KQfB/c+3A4gmpX31+7fHrbxUlRQZMVo6ar4Dol6ovUf74/rUP2ueT8zjyWS+ydf8Wlw6NKEvy+jxCealmlRxWSoXUuP1pXH5uPTgdlWKRwlq/dMHACFwb2t9tBEpmcLBJ5jd32b3+PLGKnzvD2/CjgMfYd1ttbg8cjWjDRkqSH7k6iROXbiCLbu78er3bweQ2e4dLlUHl53tvfh/XzumedmB9S2fwI+/sSyHoyJOo0IV9GtSot1+j75yGKcuXEH/4Dje+M9fiGvnlpoyfOqGCtxSUwbAejc9EJ3vzHPQfSsbEnpI7QTB5+tORRpaSbA6aeZ4GD0uS6dtaS2OnB3Eva31cdZ8ot1e9z/fbsRylc8pNC6SxB9Yxefpwe1bdnfjgwvDiExJXB65mvFEc23HUEH0BXltKTqTicsP8RAkO/5id3eckcWYLH+iQhUS5YjUd7h/ePEKAOD84FjK2KlkqZFmagdhvu5U5NIhEi/rmF2WO9t7seGnvzXcqua4LB09u3e6yz9N80tRVlyYMAu4GufO9t68XIcm1lglFlUxU8215djw09+iq28AwxOTRkmTbEs2PbY2Fu9w9xLL49JZwuRSdfBY//QBjIYnjecPr7qJRpaHyeb/fGd7L5Y9+Tp2tvcCiN50TcpoaMtja5tTLjnqVSzMTgTzOPI1lsot6NFC+nfx2/adMHJ+qJ1dibajDo1H0DS/NJrJPUG75gtwbeVcnLo4YpkFfGd7L5745VFEpmRSTxrJP6zu/Lr6BrCqqRq7OvoQmZKYJYDS2QVGzEKmy9bpFCo3FwI2a4fLhsFE96YD9GT5gVTXNKudy+r6ohKQmtPIqCXCRDdhyrnw8sFevHywNxprLCW6zgxiaCyM8rlFvtpJmAk0tGCdVNTqYqPSLqiLYaJj1YW0qqQIpy6OJMzgrpfVKZ9TiObachw5O2jp0VJGHgB8YdF8/ObkRUfr3xH3SJa0773zw9i27wSqS2fj1MUR/O1bH+GpPd2oKJltGOoqjiLdZetE6EGuVpNlJpMfjTLvs3XPcfz0zQ+1/c5AS10FjSwfkCjsRY8JNi8DKieCCm5PldhYzRf9g+O4dGUCX1g0H1UlRfh45Cr6QmMAYCRVHhqPJI3Z8juOGFpCiDYA2wEUANghpdzqRLszRToB8MD0AL5EF6Zkid901OtDY+G4XFxWHq1Naxbjz149gikJvH7sXzEanrQ8zst4XUeJSDZhKa9oZ08IW3Z348iZAUxKYHhibJqhrhtKm9YsTqotK3RdWhlJmUx++XpH6lcNucFz/zfeyFrVVJ1X5zKXeF1HVrFK+v8sAOOas+OBFZZJkM2Yb67UZ1TC0d2Ho1neI5PROL+y4gJjM5fZyMvXWCq3sB2jJYQoAPAMgP8HQDOAfyeEaLbb7kyirxcnilGxWlO2OlZf2nm5ow9DY+GE/epibamvxKY1i9FSX4n+gTGsf+Yto6/OnhD2Hu3HnEJ1uqTv4mj8oKNsUZqBlJiMXfkqSwqxobXeiHno7Amhf3AcZcUFRoJAFT+YabzDywd7LbdAZ7KNOh9juYKsoUz4wUuHsPDRX2FKs7IeXnVToC58yfCbjvSkx+p/VqUXCo2GseW1Y2l5p1VOxy2vHQMAvHd+GEfODmJZQxUKZwmsu63WiBNtqavAzQvKUo4pKDFaTgTDfwbA+1LKD6WUVwG8BOAeB9qdMfQgP/PFRgni0X94N05kqdratu8EuvoG0HVm0DKBpBLZ9v0n0XVmEOVzCnHfygaUzynEqYsj6OobMPpSbd5QVYKqkiLc/7mFln17XLye11G2GHeaWm2xgdEI3vnosuHh3L7/JE5duILhiclpOdl0/SbSgJ6EEEIY+ba27jkeFwCbLnmaSyuwGkqX+59vj8uRBURjslhWJw7P6CidDVJWSY9VeqFVTdWAEOnlnorNTyNXJ3H/8+14ak83QqNho7j0sbODOHJ2EL0fj+CDi1csr2Gqj3zNd+UWTiwd3gCgT3t+BoCnbo2SLZkkK7RptXyi0jpsaK3HOx9dBqQ0Yr9UMWgVIHjk7CA2rVls5DTZuuc4DvUOoLhQYCIijb7Mbt1Ey5v5upyTJp7XUSoSxTXpS3rHzw1hIuZ6vzQ8Huc1GhqPAFIaSQTNLnxz/hr1XP1W2eP1lCNHzw7GBcB6HN9ryA7rnz4QF/QOMON7Ajyjo0Ql4HQSXd/0NA5qFWb90wcwcnUSpbMLsPnuJXHz1OZ1zUYamlMXrqCuai7GwuNG3r9DvQMYnojguf/74TVvqcU1LNmY/IoThpaweE1OO0iIhwA8BAANDfn1j51svThZvJWVWNTOi+7+IaNWnbnmYUt9JcqKC4wdGuVzi/DmqUvG+2XFBVh547ULaLKEclZj9ah4Pa+jVCQyhPXi0srIAoDBsUjccSq32vpn3kJX3wCGxiNGpmZ1nK5XfYfhxtWL4mIA1XHNteXY1dGXMLuzxwLefa8hO5iNLO4uTIhndJROPHCqeCh9/tE1om/i0sMbVBoaAUQ9WeeG8MZ//oJRv3B0YhITk1MoEDDK6qQKrPc7ThhaZwDUa8/rAJwzHySlfA7AcwDQ2to6TbT5ii6IW2rKsGV3N0bGwyidU4TN65oT3j0or8PQeARdfQMoKy5AXdVcDI6GcW9rPV7u6DMKabYtrTXcrypniT4BWmURT2fLrsfwtY6A6YZwXDzfwV58PHIVZcUFWNZQhbc/+BjfTHQRVMlItaSk5sKw9z/fHrfDcHljVVyxcl0riZaNjF2xpq3ZeYzvNZQNO9t78We/OBL32it/9Pl8P5e5xDM6SietSyrU3NFcW45DvSFUlszG9aWz43bh9w+O49SFKygpKkBLXQU2370E3/5ZtMTO+cExo//7VjZgZ3svntrTjZqKuXjv/LCxkhPkKidOGFoHATQJIW4EcBbANwDc50C7eYNZbIotu7ujD6Q03KxK+MpN3zS/1Ag6LCyIYHgiYqSIKJ9TaCzrRKZk3G6yW2rKDFFu2d2Nrr4B9A+Oo7ZijhcueNngex3prvr7n2839NRx+nJcQelDvSFEpiS6+4csvUqb715iGGhqCdG8ZKgSouruf+Vt3bbvRJy+EqEvWXpkSdr3GsqUne29+KHJyHp41U1+nD+cJFA6UnOHutlf1lBqzCm6gQUgmtRWCGxHM2alAAAgAElEQVTffxLfXNkY5w3XbxwB4NSFK3hqT3e0Zi8QF8agJ2/2mNc8K2wbWlLKiBDiEQD7EN0K+zMpZfKI8TzG6sSby5uUFM3CoppyjExEDMNL1ZZTsVgn/zX6eumcImz9+qcNAaoAwpcP9uLVR+4AEO/p0NfcN61ZjJc7+nDy/BCA6J3DqQtXjLxbfhKn33SUDGU4FxdE96Joq4UAosGmdVVzMTQewZbXjhnufFWqRxn2iUpeqPZb6isBwDDG9OXDRLnddMwxHPm+JB0kDaXD1j3H8eybH8a91lJXwcD3FARVR+pmf+PqRca8UxyrdF9aXICCWUBNxVyMjIejoQtjYRx64i7j8/q1SxlXc2dHTYyairnTbgjNZXvy/CbOFo7k0ZJS7gGwx4m2co3VibdaB1/eWBUtAh3jgwvD6OwJGUU4AaCqpMhwl6q21JLhBxdHjB0iumHXXFuON09dMjwPKsZG93apvFv6GP2An3RkhTJYRsaj5zQ8FbWw5pfNRv/guJHaYUoC5wfHcSY0ZiT8U5NUV98AAMQZPko7hha0pUWznvVC5ip3l+6RtcJLS9J+11C67GzvnWZkNc0vNW7uSHKCpCM9t5ZKxj1yNWooqXvAkYlJjIYnsaxijlHtRO0+1D3fLXUVuHdFg+HJujIexmh4CjfPLojbuKO88cr7le83cXZhZngTibLEm9fBO3tCgBBoml+K80MTGJ6IYPv+k8Z6dYGAUaZHZ/O6ZiNIWW1t1S+Euzr6jM9XzytG9bziuB0gKrmlFzwMJB5l9LTUVxrLyVUlRagum4MzA+Nxxz54x43o7h+K81qqJUG1k3V5Y5UR9K5yawHXlhatNm5MK2SuGW7plIki+U9nT2haTFbT/FK88cdfzM2ASF6zvuUTRsoPlQS7tDjeNCidU4DWhdcMJbWsqFc2UWXF7lvZgFtqyuLDbWK7D/XAez86CxIRqKLS6eSZ0vMDJcr10dkTwrd2tBvB7I+tvRVVJUVori1HZclsFAjge39oHQeh5y9Ryzn6Fv5NaxajqqQIN82fh1MXrqC0uBDlc4sSjpF4B3WuN69rNjSw44EV+OyN16FAAPOKCzALQH3VXNy5pGbaOV7eWIXN65rj9KC8ntv2nTD0DSAuX06ixKYbVy9CS30lWuoqEhrtQct343Xuf74dX/vJ29BXo1c1VdPIIgn51ucWoqWuAi31lcY8sHldtDi9MhAGRq6i43QI39rxDt47P4wXv7sSpbOjoTQjE9H0ROrz+s3Z1q/dZsx5OvmY8NhNAuXRynQ9ONEusaHxiFHp/mxo1HCT/ry9x1ib7u4fStiu7lUwG31q54aeFiKTMdMDkb+Yl+DU4wdfOIhJCVyJaacvNGZ4mMzeS3NRaL3+ppW+9c+b31/eWGWkjEiEx1OGBIqte47HLQMBTOFAUl8TVNLsVU3Vxvtqrrrzr3+DUxeuYFIC4dg176k93dh7tB/3rmhA+dx+I3VR0/xSPPjCQVTPKzbCZxLNG14KR3CCQBlamV40EhXRbKmrQNOCeTgbGgMgDeOqpmIubi4uNJZ2zCQLtAescytlukwYlOBCL2PWwaY1i7H51SNGjFZZcUGci16/eJqLQuv1N2+piZa80LWiglqHxsLYfPeSae+nImgTolfp7AlNi8l6eNVNNLJIymtCsuvi1q/dZqR++Nu3TyMcmUJlyey49tR81nE6hNHwJCbCk3FxpbweBczQsnvRSJShvay4ADfPn5cwoFj3hHX1DeBQbwg3LyjD5nXNKY2/TMdMD0T+Y558VEzDo68cxtnQGGrK5xjHWp3PRHemllpRlQyEcMVoogc196hQBoUA8N/oyfI96f7vZXKNSZazsbt/CG+euoTrS2fjxurSaXGfyvt1/bzitPsOCkLKmc+z1traKjs6Oma8X6fQE7ypPCIq+M9K9CqTd0nRLBTMEoYHrKWuImEiSK9fwIQQnVLKVjf78KKO9J1+965owN6j/cZu1v6BMZy6OALAueBls0fUaU2pm41VTdWu3LG6rSMvakjnBy8diqtdWCCAlx9mMlIdv85Fdv/39LxXaje98oC31FXE7VDt7Alh40uH0D8whu/94U14dO2t065R5ioobs0JucKOjgLl0XIKc32pvUf7jdpxgIWLNGbMjoanormN5LU6hok+Q5erP1EpGlY1VRuaUToq03b6nB+acKQ/8y5DpzXFO9bcYi4QvWX9p2hkBQS7/3tWdRJ1D7j52DOh6I76XR19eHTtrZYxn17KuzeT0NDKgnTqH+psvnvJtXxFWhmCZILkBcyfWJ1XpaO2pbX427c+wvnBMTzmQlJJNzTFGK7com/NZ0xWsHAqFMZ8HbO6Jm1cvQj9g+M4PzhmZIJPNJ9wTpgOlw5nAK8vA2aDX931bhNErSSDS4fToUYyIyhzEXXhLnZ0FKg8Wm6TKE8XcxGRRJg1Q62QZHT2hPDgCwepETINu3NHOnkmSXbQ0EqCLryd7b1Y9uTr2Nnem/D4REIPWnI2Yo3VRKY08+ALB6MBpw5phZOm/9i65zi+9pO3p6X4IASwf51JZagluwZyvkkODa0k6MLTM3AD8cJSj9uW1mJVU7VRx0mJjpncCWA9kbUtrUXhLBFXkskJtuzuxpunLkVjA4kv+KmWJ8uqvBcJNtleZ5QB1VxbntRQM18DFfSypobB8EnQg/3eOz9sZOBWwgqNhnHk7CAary81asYFsY4TSQ9Vq3BoLGwY4dv2nUBkShoeCsd2m2qFpYm32dnei237TkCdSQHQyCJZYRXHpQyoXR19OPTEXQk/u6G1HjsOfIQNrfVxr2/ff5Je1hTQ0LLAqpi0KugMRLfJh0bDKBDRTN3V8yJxdwLZ7u5iMKO/Wd5YhfI5hXjz1CV8+2e/g6oqUFVSZHgozMZYtjqwKixNvMfWPceNjO/FBQKTMlpwnJBssLqRS2RAAfHXpO7+IUSmJLr7h+JeNyfyJtOhoWVBuiULVILJ0tkFRv6Q+59vjzPQnOyXeJ+NqxfF5a0pnCWwac3iuBpjyhhT9Q6zgVusvY+5rM5//cpSpm8gtrByAugGlBl1TRoai85XqnC0+VrFuSY5tmK0hBDbhBAnhBCHhRC/EEJUOjWwXKKCCs2xVgp1Edv69U9HK5PHasjZ3fUR1KB5v+rIiuWNVdjxwAq01FeirLgAkSmJvUf7AWBarF/QdGAHv2lIhScomCNrZvCbjsxYxXElu+6o9yAEus4MonxO1DczNB5BS10F56g0sRsM/waApVLK2wCcBPCY/SHlHiVGlbk7keFkFq1dQynAQfO+1FEiljdW4dXv346/+87KOL0oQ33v0f6g6sAOvtKQHvfyyh99Ho+6kMCWWOIrHaVDsuuOem/zuua4QtFdfQMon1vEOSpNbC0dSilf156+A+Dr9oaTX2Qaa8Xlmuzwu44SYdYLqwFkj980xLiX3OA3HTmFPldxnsocJ9M7fAfArx1sb0axygMSYA9TLvG0juzglt4CmOPGkxrSzxPnnrzAkzoi+UdKj5YQYj+AGou3HpdS/jJ2zOMAIgB+nqSdhwA8BAANDfkXa8BAdHcJio7yEb9o2+8a8st5ynf8riO3oU4zJ6WhJaVcnex9IcQDANYB+JJMUjhRSvkcgOeAaF2oDMfpOnSHuktQdJSP+EXbfteQX85TvuN3HbkNdZo5dncdtgH4LwC+IqUcdWZIuSETV30Al2JcxU86SpeZ1FAQlqG8qiEuF+YXXtWRE6Q7J1GnmWM3RutpAGUA3hBCdAkhnnVgTHlPpmkcaJilJBA60nXA4tGO4zkNsXRJXuI5HdlFzUtbXjtGLbqE3V2Hn3RqIF5AXSDbltYCSN91qi6qR84OskaZBUHRka6DTWsWA0iuIVYKSB+vaWhney+e+OXRuPJLJPd4TUfZYJ5X1LzUUl9ppHDg3OMszAyfAdkGAerZwO1k+ybeRteBypWVDAad+hdV47JwluDNF5lRzPOKVSoR1ut1FhpaGZBtEKDKBs7ac8EmUx0w6NS/bFqz2ChSTyOLzCTmecUq/yPnHmcRSTZVuEZra6vs6OiY8X7JzCGE6JRStrrZB3Xkf9zWETXkfzgXESewoyMnE5YSQgghhBANGlqEEEIIIS5BQ4sQQgghxCVoaBFCCCGEuAQNLUIIIYQQl6ChRQghhBDiEjS0CCGEEEJcgoYWIYQQQohL0NAihBBCCHEJGlqEEEIIIS5BQ8sGnT0h3P98Ozp7QrkeCvEA1Iu/4PkkuYC68x6OGFpCiD8RQkghRLUT7XkFVQV9+/6TuR6KL/C7jqiXmWGmdMTz6V/yeS6i7rxHod0GhBD1AO4E0Gt/ON6CFc6dIwg6ol7cZyZ1xPPpT/J9LqLuvIdtQwvAfwfwpwB+6UBbnmJ5YxVe/O7KXA/DL/heR9TLjDBjOuL59C15PRdRd97D1tKhEOIrAM5KKd91aDwkgFBHxAmoI2IXaoi4QUqPlhBiP4Aai7ceB/BDAHel05EQ4iEADwFAQ0NDBkMkfoA6Ik7ghI6ooWDDuYjMNEJKmd0HhfgUgH8CMBp7qQ7AOQCfkVKeT/bZ1tZW2dHRkVW/xBsIITqllK1pHEcdkYS4rSNqyP9wLiJOkK6OrMg6RktKeQTAAm0QpwG0SikvZdsmCR7UEXEC6ojYhRoibsE8WoQQQgghLuHErkMAgJRyoVNtkeBCHREnoI6IXagh4hT0aBFCCCGEuAQNLUIIIYQQl6ChRQghhBDiEjS0CCGEEEJcgoYWIYQQQohL0NAihBBCCHEJGlqEEEIIIS6RdQkeW50KMQzgvRnvGKgGkKssv7nqO1f93iKlLHOzgwDqKGj9Ai7rKIAaymXfnIucJ2jnMpd9Z60jxxKWZsh72dYMsoMQoiMX/eay71z2OwPdBEpHQetX9e1yF4HSUC775lzkPEE7l7ns246OuHRICCGEEOISNLQIIYQQQlwiV4bWcwHrN5d9+7lfP/9t7Hdm+uZ3yn690gf7zW3fWfebk2B4QgghhJAgwKVDQgghhBCXmBFDSwjx50KIs0KIrtjP2gTHtQkh3hNCvC+EeNSBfrcJIU4IIQ4LIX4hhKhMcNxpIcSR2Niy3lmQavxCiGIhxK7Y++1CiIXZ9mVqt14I8c9CiONCiGNCiI0Wx3xRCDGonYMnHOo76XcnovyP2N98WAjxB1n2kxMNxdr0vY5yqaFY277WURA0FGvX93NRrC3qCJyL0taRlNL1HwB/DuBPUhxTAOADADcBmA3gXQDNNvu9C0Bh7PFfAvjLBMedBlBts6+U4wfwHwE8G3v8DQC7HPp+awH8QexxGYCTFn1/EcBuF85t0u8OwFoAvwYgAHwWQLuXNBQUHeVSQ0HQURA0lGsdzZSGqCN3deTHuSiflg4/A+B9KeWHUsqrAF4CcI+dBqWUr0spI7Gn7wCosznGZKQz/nsAvBB7/A8AviSEEHY7llL2Syl/H3s8DOA4gBvstusQ9wB4UUZ5B0ClEKLWpb4c1xAQDB3luYYAj+soCBoC8l5HM6khgDrKijzXEJCFjmbS0Hok5mb7mRCiyuL9GwD0ac/PwNkv9zuIWqFWSACvCyE6hRAPZdl+OuM3jon9swwCuD7L/iyJuW6XAWi3ePtzQoh3hRC/FkIscajLVN+dk+c11xoCAqCjHGgICJaOfK8hwPdzEUAdxR3DuSgxjmWGF0LsB1Bj8dbjAH4CYAuif8AWAH+FqEjimrD4bMotkcn6lVL+MnbM4wAiAH6eoJnbpZTnhBALALwhhDghpXwzVd/moVi8Zh5/Vn9j2gMQYh6AVwD8QEo5ZHr79wAapZRXYvEErwJocqDbVN9d2n9zrjSUqu8g6ShHGgJ8oCNqSGvc43MRQB2Bc5EjOgIcNLSklKvTOU4I8T8B7LZ46wyAeu15HYBzdvsVQjwAYB2AL8nYAqtFG+divy8IIX6BqMs0U1GmM351zBkhRCGACgCXM+zHEiFEEaKi/LmU8n+b39eFKqXcI4T4GyFEtZTSVs2oNL67tM9rrjSUTt9B0FGuNBRrz/M6ooai+GEuirVDHXEusq0j1ajrPwBqtcf/CcBLFscUAvgQwI24Fni3xGa/bQC6AcxPckwpgDLt8dsA2rLoK+X4AXwf8YGDLzv0/QoALwL4cZJjanAtb9pnAPSq5zb6TfndAfgy4gMHf+clDQVFR7nSUFB0FAQN5VJHM6kh6shdHflxLrI1qAwG//cAjgA4DOAflUgBfALAHu24tYjuMPgAUTep3X7fR3QttSv286y5X0R3VLwb+zlmp1+r8QN4EsBXYo/nAPhfsXH9DsBNDn2/dyDqujys/a1rATwM4OHYMY/E/r53EQ2i/LwD/Vp+d6Z+BYBnYt/JEQCtXtJQUHSUKw0FRUdB0FAudTSTGqKOOBdlqiNmhieEEEIIcYl8Su9ACCGEEOIraGgRQgghhLgEDS1CCCGEEJegoUUIIYQQ4hI0tAghhBBCXIKGFiGEEEKIS9DQIoQQQghxCRpahBBCCCEu4Vitw0yorq6WCxcuzEXXZIbo7Oy8JKWc72Yf1JH/cVtH1JD/4VxEnMCOjnJiaC1cuBAdHR256JrMEEKIHrf7oI78j9s6oob8D+ci4gR2dMSlQ0IIIYQQl6ChRQghhBDiEjS0CCGEEEJcgoYWIYQQQohL0NAihBBCCHEJxwwtIUSBEOKQEGK3U22S4EEdEbtQQ8QJqCPiFE56tDYCOO5geySYUEfELtQQcQLqiDiCI4aWEKIOwJcB7HCiPRJMqCNiF2qIOAF1RJzEKY/WjwH8KYAph9ojwYQ6InahhogTUEfEMWwbWkKIdQAuSCk7Uxz3kBCiQwjRcfHiRbvdEp9BHRG7UEPECagj4jROeLRuB/AVIcRpAC8B+LdCiP/PfJCU8jkpZauUsnX+fFfLThFvQh0Ru1BDxAmoI+Iotg0tKeVjUso6KeVCAN8A8H+klP/e9shIoKCOiF2oIeIE1BFxGubRIoQQQghxiUInG5NS/guAf3GyTRI8qCNiF2qIOAF1RJyAHi1CCCGEEJegoUUIIYQQ4hI0tAghhBBCXIKGFiGEEEKIS9DQcpnOnhDuf74dnT2hXA+F5DnUCskXqEXiRfJVtzS0XGb7/pN489QlbN9/MtdDIXkOtULyBWqReJF81a2j6R3IdDauXhT3m5BEUCskX6AWiRfJV93S0HKZ5Y1VePG7K3M9DOIBqBWSL1CLxIvkq265dEgIIYQQ4hI0tAghhBBCXIKGloa+YyFfdy+Q4NDZE8L6pw9g/TNvUYckr3B6fuR8SzJhZ3svlj35Ona29+Z6KGnBGC0NtWNBoR7n45ov8T/b959E15lB4zF1SPIFfa50QpdOt0f8zbZ9JxAaDWPbvhO4b2VDroeTEhpaGlY7FvJt9wIJDhtXL8LQWBgQgjokeYXTu7vydbcYyU82rVmMbftOYNOaxbkeSloIKeWMd9ra2io7OjpmvF8ycwghOqWUrW72QR35H7d1RA35H85FxAns6IgxWoQQQgghLmHb0BJC1Ash/lkIcVwIcUwIsdGJgXkFBnE6Q9B1ZBfqkBpygyDqijrKL/ygQSc8WhEAfyylvBXAZwF8XwjR7EC7niBfU/57kEDryC7UIQBqyHECqivqKI/wgwZtG1pSyn4p5e9jj4cBHAdwg912vULb0lpUlRShbWltrofiaYKuI7tsXL0Iq5qqswom9sMdI0ANuYFZV37RSjKoo/xAaa1taW3Wc1u+4OiuQyHEQgDLALQ72W4+s/doP0KjYew92u+JbaZeIIg6soud0hN+3FpPDTmDWVd+1EoyqKPc4SetORYML4SYB+AVAD+QUg5ZvP+QEKJDCNFx8eJFp7p1nEzv2Ox4Esh0/KKjbMiVt8BvGg6yhpzESo9+00oyqKPc4CdPlsKR9A5CiCIAuwHsk1L+darj83kr7P3Pt+PNU5ewqqnaUSu6syeE7ftPYuPqRVjeWOVYu/lKNlth/aSjbFDaa6mrQPncosBoJRmZ6ijoGnKSRHOh1+YyzkXeQOlqaCyMrjODjl+D7WInvYPtpUMhhADwPIDj6Qgy33ErcZ6f3KBu4DcdZYPS3NB4hFrJAmrIWRLNhX6fy6ij3KB01VJf6RtPlsKJpcPbAXwLwL8VQnTFftY60G5OUDEJmd6pJVv26ewJYWgsjJb6yjjxJPpMqiUknwak+kpHmaDO53vnhwEA97bWY1VTNdqW1s7oeU5XV3msv8BqyA2WN1Zh4+pF2LK7G+ufPoCd7b0Jl3TsaiLPNEUdzSD3P9+OhY/+CkNjYaxqqsbmdc1ZXYPzGdseLSnlAQDCgbF4mmR3eapm3aqm6jjxJPpMqjtGP95RBllH6nweOTuI0GgYQPS8qqUb9XymxpGqv3zVX5A15Bbb959EV98AAKDn8ok4fZqPs6OJfNIUdTSzqPPedWYQp7d+OcejcQfWOrSBHquQbMkx0XvqufJcqJgHq+PT7Yt4D1XTcOTqJBqvL512fs3n2W6MTKLPp6sr6s9b2NHLxtWLMDQewch4tOZmdelsDI1H0NkTyko7yfqx83niTbbuOW48XtVUncORuAtrHdrAqcD5dNpxK0jfLVhfLDMyOb92teAlLbHWoX2cON+qjaqSIoRGw57QjoJzUf7yyR/uQWRKonCWwPs/yu/VWdY6nCHMcQTJtjrvbO/Fsidfx8723qRt7mzvxaHeEJoWzEt6NxekbdV+J9G2+Zb6SgyNhRPG+anPJEoiqWJoUsW5UEv+Jx296Dqxek2fw1Qbm9YspnaIbVRcVk15MQpnCTx4x425HpKrcOkwA7a8dgxdZwYxNBbGq4/ckTRJ5LZ90XiGbftOJE1kum3fCQxPTKLwykRSt76dhJQkv1DxKENj4bg0DuVzCo1SE6liYKxi+swxXomglvyPrpd0dg1avabPYYeeuMt4nYmZSbaoZWyltTMD476Ny9KhRysThIj/nYRNaxajqqQIm9YsTnrchtZ6FM4S2NBa78QIiQdQ3gEIEVfDK5mnKZ33NrTWsxwUARCvF3OtOCstWb1mnsPybGcg8SBbXjuGN09dwrziAgD+jsvSoUcrAzavazaCShOhB54eeuKupO3tbO/FjgMfITIl0d0/LfEw8SnKo6RrRX892WeSvXf/8+2W5aBUP8215djV0YdNaxbTK+FzdL2kCjS3Cpbv7Alh79F+7HhghfFaPu0MJN5i657j2HHgI1SVFgEAPrmgDK9+//Ycj2rmoEcrA9SOwO37Tya8q8uk0vi2fSeMQEDGPAQPPWebE96CRF4vpckdBz4yloJIcDHPUVZzltVrjO0j2dDZE8Kzb36IyJTE5StXjVxZQYIerQzo7AnhwRcOxsXBmO8G25bW4sjZwbjlm0TbqzetWYyn9hxHTXmx8drO9l5s23eCXoeA0NkTwpbd3Th5fgij4Sl0nL6MRf+mDJvvXpLxVvxEXi91YbyudDZ2H+6PW6b2WjkVkhyzl3TL7m58cGEYwxOTOHJ2EDseWGGZPmRoPGJsxNBTzOipZwjJlDv/6l9w6uKI8fx7f3gTHl17aw5HlBvo0cqA7ftPIjQaRlVJkTHxmO/89h7tN5Zv9M9ZebnuW9mAZQ2VOHVxxHhPD0Al/kclhBwNTwEARsNT6DozmJZHNF2UAXZ55Oq0ZepMPLAk/9HPp9LW8MQkCmcJhEbD2L7/5LTqF2ojhq47dczeo/1x7VErJBN0I+uVP/p8II0sgB6ttNHTMGz92m3GJGX2YKnkk/2D41j/zFvYvK45YWJSdbz+e0NrPXYc+IjB8QFh4+pF6B8cx9nQKK6bV4y5RQUonV2QMp6mbWktXj7YCwiBzeua42JrEnmorGJ1rDywifqk1yv/0c/xe+eHcag3hIqS2RAABkavorm23Cijs/dof1x9zZa6CmxcvShlcmR6t0gqlCercBYQmQKa5pcGeu6goWUi0UUlURoG3YN138qG6N3h3CJ0nRkEAGOrfqKSKublnu7+IQbHB4jljVWorZiDUxeuoLW6NE4LVlq0SuWgp4NIFrBstbRo1q8VDIL2Dvo53r7/ZHTOKogYWtnV0YfQaNjQz9B4BD0fjxhJSJc3Vk2bp/RzzvNPUtHZEzI8WZEpBCJ9QyoCtXSYTsCx7h7Xj0+UrqFtaW3clnpVQLppwTw0LZiHobEwdrb3Yv3TB9A/OI6W+sqkxYIZcBo8mmvLUThLoLm2PO51pcUHXzg4LUnupjWL0VJXMa1Qua5Hs94TJUpVekv0/5FMk9zyn3v0c2BOVNpSV4HqecVoWjAPdVVzMToxiZKiWdgQK1wOKREaDaNwlojzyvN8k2z5d8/91njcNL80hyPJHwLl0Up0Z57IVa6OP9Q7gJvnl2LTmsVG7NXeo/1ori030jNs23cCt9SUxRWQBqIFM4+eO4rIVLTUUVlxIZ7a043hiclp4wCYTNKPmD1T5ue7OvoQmZLY1dEXF8OwcfUiHOoNITQaxpbXjuHeFQ3Ytu8ENrTWY+/Rfty7oiEuFhCI91Cp+JojZwexac1iI/4PSF6sXAVN6zE8iTRJb1fuUeeg43QIE5FJTMaqqr343ZWGd72qpAiRSYmJySlgEvh5ew/+7jsr8d75YWN+empPN17u6MPmdc2W59JqM5D+HpeXg83SJ/biytXJuNfe+OMv5mYweUagDK1E+WQSZd1uW1qLtz/4GMMTEXSdGTSq1yu3+9sffGwYUCrQVI95uaWmzDi2rLgAgMDwRAQA4gLqib8x68v8/AuL5uPVrnP4wqL5cZ9b3liFmxeUoatvABDCMJSUcW+VCd6scXWM+qxZd+YM4up4q+z0VrAY8MyRrBi4rgWVLkZ518uKCxAaDaNpfilGL0UwKYHhiUkjqF2lmBmemERX30DCc2+1GUh/jwZ3cNnZ3jvNyKqrnJOj0eQfgTK0Um1/N08ee4/2IzIlUVZciCq3q7kAABkpSURBVJvnlxoeBBVIqhJAfmHRfPzm5EXjdT3mZccDK6Ztt4aUxvb9zp4Qtrx2DBAC98Y8Fbwr9BdW2+n13785edH4rRL7PXjHjXh07a1xSXLfOz9seLS6+4emBTQD0zWu9Kcfa75Iq9/LG6um6TUR+kWfF9aZYcvubnT1DWBoPBKX7FGdt0dfOYzzg2N4bG2zEWvVdWYQLfWVKJ9TGDcHjUxE0D8whvHIFMqKC/DNlY1458OPAZE4p59ZK4neI8HiBy8dwqtd54zn82YX4OiTbTkcUf4hpJT2GxGiDcB2AAUAdkgptyY73iuVzpO5w/X31N2cXvIiXWNJDzytKikyglK9fvHKptK5X3WUip3tvUY+tQ8vjWBSIu+r2Svduq3VTHXkZw2tf/pA1HCqq8Crj9yR8Dh9Z2qiGzd93gHgizknEZyL3GXho78yHv/oq5/ybf7HbHSksO3REkIUAHgGwJ0AzgA4KIT4Ryllt922Zwpzkr9Uk5Q6Rl9yGRqL7uABrrnOE8XmtC2txcsdfYCU+OxN1xtbsAEgMinRXFuO9U8fiNu6n87k6WX8oKNM0ZPT3rxgHrr6Bgxj+/M3Xz8tFYjyfl4auYrLV67ihso52Pr1TwPANP2mo49UcTW6t1VPIQHkpwfD7xrafPeSad7GZDtTD/WGcPOCMuPYqEHfjcqS2ZAASopm4fp5xZhTOAtD4xHsbO+Nm1vMyZPTSabsh1gtv+vIKW5+7FdGPCAAzC+b7Vsjyy5OLB1+BsD7UsoPAUAI8RKAewB4RpS60QRg2vb5RMuNKpsyAJTPLTJ2Kybaam+1Nb/n8mjCLdiqjUSf9dkdqOd1lC7qYnSodwDDExFs23cCjdeVAAAik9HEpVbnWW20UOiJbs361T+XiFRxNXp/5ridPN204TsNmQ0X83dudQ71mC095kqlqBmeGDM+31od3RX25qlLRpoH1ZaePPm+lQ3Tnlvhk1gt3+nIaTp7QnFGFnfKJ8cJQ+sGAH3a8zMAPPUfphtN966ITiDK66SXpdBR2ZSVcaXf4auyKiMT15IAqvf0tpVHa1dHHza01uOdDz/GyNVJjIUnMXo1ggIxK27LtfqsOS7HJ3heR+miLkZN80tROCKi5/6jy9Gt0EKgRkpACDReVzItdcOh3hDmzi7AlfFJ3FA5xzKRpPKuqi345rhA4FoaEnN6CB3lqU0Wt5NneFpDVp71obGwYeymE1+q2ti0ZjFePtiLkauT0eTJTx/AhtZ6vPjb05iUwPyyYlSXzp6mL31uUTtVVUobczJlK+9VPno6s8DTOnKbO7b+E84MjBvPC4SnjeoZwQlDS1i8Ni3wSwjxEICHAKChIb/ci7rRVD633xCNXn6ibWmtEYi8+/A59A+O4/ZPVqOqpAjNteVxE879z7dHd4oBRhJA1Y9qW90Rrn/mLYRGw8Z263jv2mRcIlTzZ32G53WUCnVhaq4tx5Gzg/jSrf8G3f1D2H34HM4MjKO4cBYmIlPG8bp2gKgehycmsaxhumdDjw1U3tUHXziIxutLDS2ava0qDUmiJZ7ljVVJY4HyEE9ryMqz3lJfiZa6CgyNR7B1z3Hs6uiLW7rTC923La01UscMjUfw6iN3xMVifXBxBAWzBEYnJnGTKTmuqtuqpwu5b2WDkbLmlpqyacmUrbxXeerpzBRP68gtVvzFG7h45Wrca6/80ec9u0Q8kzhhaJ0BoNeLqQNwznyQlPI5AM8B0cBBB/p1lGSlJjauXmTkj1Fb64FrSzT6Up/yAjQtmJe0lAoQvfB+cGEYwLXt1urzI1cnjc/7PT4rhi90lAzz8q/STUFsWg9rRlaBmF6yKZm3IFGahsbrJFrqKwEpjfbaltam9GZ5FE9rKNEcpM7t0bODRs4+/WZL7UaMLkVHt9iPxNLIKG99tLB09LWy4gIjkbI+n1gZTmZdJfvtIzytI7cwG1l1lXP8eB1yBScMrYMAmoQQNwI4C+AbAO5zoN0ZxepOTH9t05rFeGpPNypKZuPKeBgDY9FlwZ7Lo8Z2++bacmz46W8RmZLGLp6d7b148IWD2LRmMW6pKYsLLlYlMlT6CDXhmb0I6q7Ux/FZgE90lAzdiG68rsRYNlbpQdTSzmh4CsWFBXj5YK+xbKR7LRLlUtJ/V88rRmRyCveuaMB9KxvQ2RPCt3/WjuGJSRzqDWF4YjKpN8ujeFpD5jlIP+cAjHQyenUK/WatprwYVy9PYmJSYuxqxDimfE4hvrmyES/+tgeARE3F3Li8gEB0PrEynKLL1QPoHxgzjks0Xh/haR25wYq/eCPuOT1ZmWHb0JJSRoQQjwDYh+hW2J9JKY/ZHlmecd/KBmMpsaqkCEA0kD00GkZ3/xBe/O5KLHvydSP5n5qs9ADST91QERdcnCwvjU4A4rMCoSO9Duaqpmp09w8hNBrG5ZGrOPTEXQCAO5fUXMu+LURcypBkxrZ+0bv/+XacunAFAIylZ2XUA0BNxVwsq5jjOx35TUNWHia9coA6ZnhiElUlRdj69U/j2z/7HSYmIxgci8S1ceTsIEbD0fNfWlyIVU3V0+aTRLUwhyciGL4YSTuJrdfxm46cQPdmrW/5BI2sDHEkYamUcg+APU60lWv0AE+VIFLFROgGz9++9RF6Px5FSdG1gPWo1yuaD+m988PYvv8kNrTW4+ftPaieV2ws2ajgYvPElmpr9C01ZX6NzwLgLx2ZUakSRq5OoqW+Es215Xjxt6dRUlQQVydTD2QGYHiw1DHmi6O+5V7F05h1BsQHtptTNfgJP2lI36RjtSFHHaN+L2+swmNrb8Vf7O7GeHgSzZt/jbuW1KCsuBCFswRKigpwQ9XcuPNvnk9UCoiairnY+rXbjDFASt8Z5snwk47sYC6rM3/ebPz4G8tyOCJvEqjM8Omg30Xq5UvMAenb9p0w6oYpr4Hu9Xpqz3EMT0QwNB7BsoYqvHnqEvYe7U8aXGx1B5usvhjxDnqqhFVN1djV0YfRcDQma+/RftxSUxZ3nlVA+wcXrhg6UtnA9Yuj2WOq9GPWmQcD2wOPeWez1f+++WZNpWEYDU8iPCWx+3C0usXwRPT92orEcTWdPSE88cto3cPhC1ewZXc3yucU+towJ9aoG0PdyDq99cs5HJG3mZXrAeQbG1dfq1y/ac1iVJUUGTEReuX6TWsWo6y4EE3zS40g486ekPH5mvLiaIOxO0HVpt5Gsr5Vf+riy9qI3mbj6kVoqaswAtA3tNajQAB1VXONpUFVE3NoPIK2pbVoqavA5FQsQD5BBQddo2b9WJFMf2TmSPc8pHNOzWxasxglRQUomiUgBFBcMAt1lXNSbn7Yvv8kIlMSBQJoWjAPkNIw8kiwePjvO+Jy9s2bXZDD0XgfR0rwZIpXyxUkKjti9XqiZcBEbehLSwBQGhN215lBVJUUYccDKzx1V2mnXEG6eFVHwHQdqPN/8l+vYDQ8iQIB3DR/Hk5duOLo+Z+p0jlO4baOcqWhmTgPy5583fCQplMezJzHS8+/Zn7OuSgeL89FZsy1Cxn4HsWOjujRygB1d6l7sBK9rlz6qnyO7vFqWjAPHacv486//o3RhlpaOnXhCk5duBK9m4gFQ29asxjb9580jqVXwpvo561taa2Rg239M28ZRrYKWJ6UwKkLV9C0YJ6jRnY2HhLiPInmklSY//fV853tvdPaMXvdv/2zqHG35bXpcd3mG8Pt+0+iq28A5XOLsLyxClteO4auvgF0nRmkh8un3P98OxY++qs4I4uB787AGK0MUMaTngRQGVNWryvMsVeXrkxgNDyFUxeuGLEXG1cvwocXr+Dc4Diq583GJyquBa3q6R12PLDCL2UuAoc5IWU0UW2vkd+owCJN4qUrE45OdD7eku8pUs0ZiUinrJee2FjF893/fPu1HFta3A2AuNQfQ2NhvPrIHdNTPYioOMuKk+cGJN6ksycUNzcBUSOLge/OQEMrCxIl6kv3dZWTq6ZiblxC0sGxMKYkcHkkjJ/8+9a4shZqIlU5uaz6IfmNlT76B8YwfDGCAgGjdljRLCA8BRTOEnE5k4j/yDTpZ6JkoVapX/RKBId6B1BcIDAxKY2wBIWe+kMZVGaDXOX982my5EDT2RPCt3a8E/faw6tumpZKhGQPlw4tSLU0p7J0b9ndjfVPHzCOM+cySvT5+1Y24O++sxK1FXMAXLtLramYiwIBRKYkvrXjHax/5i1s3XMcD75wEBta61FVUoTQaDhaJ5F4FpX6Q6VsKCsuxN2f/oTxfngKKCkqwJP3LM06nUeyJSWSH6RK56KOUedPJT9uW1obV9Zr4+pFcRne1WcefeUw3jx1Cc+++SGGJyKYXViAVU3V2Hz3kmnhDGqjxuZ1zZZ966EQxF98/SdvGzugAeBHX/0UjSyHoUfLgnSW5lQMg3qcbKkwk9IWW147hq4zgxgNT6Grb8Aou7Gro89YNhwaC3Pp0IOYl3n05Z7fnLwYd+xo+FqdSyf6AqiVfCPdeSZRuplE7ajnZcXxnqvH1t4at5Sof8Yq9QdDFIKBvh3uR1/9lK9zNeYKGloWpOPOT5bIz8q9ryceBICh8WgJH3Pi0s13L8GW3d0YGQ+jdE4RPnvjddPKbty7ogHlc/2ZId7PmJd52pbW4uWDvUbMjITEwGjE2HFo5/wGoZqA10l3nlG/9QTKis6e0LS6lfq5/5t/PoX+wXF87w9viruAZpoMNRnpeOZI/rF1z3HsOPCREbYwt3AWjSyXYHqHGULfzg0g7XQQOuufPoCuM4NoqavI++ST3FKdPkobhbOEUcJp13/4XEYXLb9e7Pya3sEp7KSJsJpPstFRvqcM4Vw0nZ3tvfjhL44AiMaCvv+jtTkeUf7D9A45IpM0C2o7f9vSWsst9spNr7ZOW7YdC1Q1fhPPsbO9F8uefB0723uN15QeHrzjRsPYevCFgxnFVZn1Q/KbTOaOTJIcZ4TFfKJ0tOW1Y2mPjylDvENnTwh3/vVvDCMLAB6848YcjigY0NCyQSYXt71H+xEaDWPv0X7LwFLzZGXV9uZ1zVjVVI17W+sZ4OxR9JI5CqWHR9feil3/4XMoKy5AaDQcTRCZJrzYeYtM5o5kx9oJUr83tsHm3tZ64zWlIwiR9vgYKO8NVKURVXAeYOD7TMEYLRtksjU71bHm7dRWx2ebe4fkD5vWLJ4WZ6OzvLEKN8+fF01Ym8GyPvNjeQsn545s0W/+VGyO0pE5SzzxPqrMV0nRLBTMEnhsbTNjsmYIGlo2yOTilsmxqeIkkk28fo3V8Qt6EkkzehmmlroKo/QJ8R9uzB2Z/O939oTiNuTYGR/Jb3a292LbvhPYEPNc8tow89haOhRCbBNCnBBCHBZC/EIIUenUwIJMqmWFZK56L8bqUEdR9DJMqvQJSQ9qKPPlSL3EDoniRx2pcIVdHX1c4s0RdmO03gCwVEp5G4CTAB6zPyRiJ97Go7E61BEQlzjSY+cvHwi8hjL53/foPDET+E5Hm9YsRlVJEatM5BDH0jsIIb4K4OtSym+mOtZrW2HzBS8tC2a7FZY6chcvaQjITkfUUOZ4TReZEMS5yM/nM1fkS3qH7wD4tYPtERNeXBbMAurIRaghYkVAdJEpntURz2d+kTIYXgixH0CNxVuPSyl/GTvmcQARAD9P0s5DAB4CgIYG7nTIBrd2H80E1FF+QA1RQ1Z4WReZEgQdBel8egHbS4dCiAcAPAzgS1LK0XQ+k29uVrcJohs3UzcrdRQliFpJRiY6CoqGqJHMCMpcRF24S86WDoUQbQD+C4CvpCvIIOK0GzeTrNJegDq6htJKppnhg06QNGRnPvHb3OE0XtWRSkbK5cL8xG6M1tMAygC8IYToEkI868CYfIfTO3x8uP5OHcXYuHoRqkqKEBoN++n8zgSB0ZCd+cSHc4fTeFJHKhlpVUkRlwvzEFsJS6WUn3RqIH7G6eR/idbfveo6po7iabyuBI3XC06YGRAkDdmZTzauXoSh8QiGxsLo7Al5ap6YCbymIzXnty2tBcBkpPkKax3OME647hMlLOXdqvfZsrs7Wn4H4IRJ0ibdeWV5YxXK5xSi68wg5wmPoy8X7j3az2SkeQxL8MwwyhgCnK9TyJ0mPkBtTnEovx0JBpnMK5wn/AGXC70DPVo2yMY75WZG5mSleUjuSUcvm+9eglVN1axz6AHyKbA8k3mF84S3UbprW1qLVU3V2PHACp7LPIceLRtk451isdbgko5eqA/v4KZ3OlOom+CQT7oj6UFDywZ0wZNMoF78Bc8nyQXUnfegoWUD3kWSTKBe/AXPJ8kF1J33YIwWIYQQQohL0NAihBBCCHEJGlqEEEIIIS5BQ4sQQgghxCVoaBFCCCGEuAQNLUIIIYQQl6ChRQghhBDiEjS0CCGEEEJcgoYWIYQQQohLOGJoCSH+RAghhRDVTrRHggl1RJyAOiJ2oYaIk9g2tIQQ9QDuBNBrfzgkqFBHxAmoI2IXaog4jRMerf8O4E8BSAfaIsGFOiJOQB0Ru1BDxFFsGVpCiK8AOCulfNeh8ZAAQh0RJ6COiF2oIeIGhakOEELsB1Bj8dbjAH4I4K50OhJCPATgIQBoaGjIYIjED1BHxAmc0BE1FGw4F5GZRkiZnXdUCPEpAP8EYDT2Uh2AcwA+I6U8n+yzra2tsqOjI6t+iTcQQnRKKVvTOI46IglxW0fUkP/hXEScIF0dWZHSo5UIKeURAAu0QZwG0CqlvJRtmyR4UEfECagjYhdqiLgF82gRQgghhLhE1h4tM1LKhU61RYILdUScgDoidqGGiFPQo0UIIYQQ4hI0tAghhBBCXIKGFiGEEEKIS9DQIoQQQghxCRpahBBCCCEuQUOLEEIIIcQlaGgRQgghhLhE1iV4bHUqxDCA92a8Y6AaQK6y/Oaq71z1e4uUsszNDgKoo6D1C7isowBqKJd9cy5ynqCdy1z2nbWOHEtYmiHvZVszyA5CiI5c9JvLvnPZ7wx0EygdBa1f1bfLXQRKQ7nsm3OR8wTtXOaybzs64tIhIYQQQohL0NAihBBCCHGJXBlazwWs31z27ed+/fy3sd+Z6ZvfKfv1Sh/sN7d9Z91vToLhCSGEEEKCAJcOCSGEEEJcYkYMLSHEnwshzgohumI/axMc1yaEeE8I8b4Q4lEH+t0mhDghhDgshPiFEKIywXGnhRBHYmPLemdBqvELIYqFELti77cLIRZm25ep3XohxD8LIY4LIY4JITZaHPNFIcSgdg6ecKjvpN+diPI/Yn/zYSHEH2TZT040FGvT9zrKpYZibftaR0HQUKxd389FsbaoI3AuSltHUkrXfwD8OYA/SXFMAYAPANwEYDaAdwE02+z3LgCFscd/CeAvExx3GkC1zb5Sjh/AfwTwbOzxNwDscuj7rQXwB7HHZQBOWvT9RQC7XTi3Sb87AGsB/BqAAPBZAO1e0lBQdJRLDQVBR0HQUK51NFMaoo7c1ZEf56J8Wjr8DID3pZQfSimvAngJwD12GpRSvi6ljMSevgOgzuYYk5HO+O8B8ELs8T8A+JIQQtjtWErZL6X8fezxMIDjAG6w265D3APgRRnlHQCVQohal/pyXENAMHSU5xoCPK6jIGgIyHsdzaSGAOooK/JcQ0AWOppJQ+uRmJvtZ0KIKov3bwDQpz0/A2e/3O8gaoVaIQG8LoToFEI8lGX76YzfOCb2zzII4Pos+7Mk5rpdBqDd4u3PCSHeFUL8WgixxKEuU313Tp7XXGsICICOcqAhIFg68r2GAN/PRQB1FHcM56LEOJYZXgixH0CNxVuPA/gJgC2I/gFbAPwVoiKJa8Lisym3RCbrV0r5y9gxjwOIAPh5gmZul1KeE0IsAPCGEOKElPLNVH2bh2Lxmnn8Wf2NaQ9AiHkAXgHwAynlkOnt3wNolFJeicUTvAqgyYFuU313af/NudJQqr6DpKMcaQjwgY6oIa1xj89FAHUEzkWO6Ahw0NCSUq5O5zghxP8EsNvirTMA6rXndQDO2e1XCPEAgHUAviRjC6wWbZyL/b4ghPgFoi7TTEWZzvjVMWeEEIUAKgBczrAfS4QQRYiK8udSyv9tfl8XqpRyjxDib4QQ1VJKWzWj0vju0j6vudJQOn0HQUe50lCsPc/riBqK4oe5KNYOdcS5yLaOVKOu/wCo1R7/JwAvWRxTCOBDADfiWuDdEpv9tgHoBjA/yTGlAMq0x28DaMuir5TjB/B9xAcOvuzQ9ysAvAjgx0mOqcG1vGmfAdCrntvoN+V3B+DLiA8c/J2XNBQUHeVKQ0HRURA0lEsdzaSGqCN3deTHucjWoDIY/N8DOALgMIB/VCIF8AkAe7Tj1iK6w+ADRN2kdvt9H9G11K7Yz7PmfhHdUfFu7OeYnX6txg/gSQBfiT2eA+B/xcb1OwA3OfT93oGo6/Kw9reuBfAwgIdjxzwS+/veRTSI8vMO9Gv53Zn6FQCeiX0nRwC0eklDQdFRrjQUFB0FQUO51NFMaog64lyUqY6YGZ4QQgghxCXyKb0DIYQQQoivoKFFCCGEEOISNLQIIYQQQlyChhYhhBBCiEvQ0CKEEEIIcQkaWoQQQgghLkFDixBCCCHEJWhoEUIIIYS4xP8PHwwPZ71WI5YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points = inputs_points\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "use_lim = True\n",
    "lim = 5.0\n",
    "\n",
    "for i in range(axes.shape[0]):\n",
    "    for j in range(axes.shape[1]):      \n",
    "        ax = axes[i, j]\n",
    "        if use_lim:\n",
    "            ax.set_xlim([-lim, lim])                \n",
    "            ax.set_ylim([-lim, lim])\n",
    "        ax.scatter(points[:, j], points[:, i], s = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = np.mean(image), np.std(image)\n",
    "image = image - mean\n",
    "image = image / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Batch normalization__ \n",
    "\n",
    "$$x^{(k)}=\\frac{x^{(k)}-\\mathbb{E} \\left [x^{(k)}\\right ]}{\\sqrt{\\operatorname{Var}\\left [x^{(k)}\\right ]}}$$\n",
    "\n",
    "$$y^{(k)} =\\gamma^{k}x^{(k)}+\\beta^{k}$$\n",
    "\n",
    "* Ускоряет и стаблизирует тренировку\n",
    "* Регуляризует\n",
    "* Не так важна инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>     \n",
    "    <img src=\"./img03/prec_rec_1.png\" alt=\"Предобработка данных\" style=\"width: 250px;\"/>\n",
    "    <strong>Предобработка данных</strong>\n",
    "</center>\n",
    "\n",
    "* Правильные ответы:\n",
    "    * TP - истино-положительное решение\n",
    "    * TN - истино-отрицательное решение\n",
    "* Ошибки:\n",
    "    * FP - ложно-положительное решение (false positive) / ошибка 1го рода\n",
    "    * FN - ложно-отрицательное решение (false negative) / ошибка 2го рода\n",
    "\n",
    "\n",
    "* Тривиальная метрика качества в двухклассовой классификации: $Accuracy=\\frac{correct}{total}$.\n",
    "    * Проблема: при несбалансированном наборе данных (обычно он всегда такой!) тривиальный ответ может давать высокую Accuracy.\n",
    "* Улучшенные метрики качества:\n",
    "    * $Precision=\\frac{TP}{TP+FP}$ - точность \n",
    "    * $Recall=\\frac{TP}{TP+FN}$ - полнота\n",
    "\n",
    "\n",
    "* $F_1=2\\cdot\\frac{Precision \\cdot Recall}{Precision+Recall}$ (в диапазоне от 0 до 1).\n",
    "\n",
    "* The general formula for positive real $\\beta$, where $\\beta$ is chosen such that recall is considered $\\beta$ times as important as precision, is: $F_\\beta = (1 + \\beta^2) \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{(\\beta^2 \\cdot \\mathrm{precision}) + \\mathrm{recall}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Перекрестная энтропия__\n",
    "\n",
    "В задаче классификации мы хотим оценить вероятность различных исходов. Если ожидаемая вероятность исхода $i$ это $q_i$ при том что частота (эмпирическая оценка вероятности) исхода $i$ в тренировочном множестве это $p_i$ и всего в тренировочном множестве имеется $N$ исходов тогда правдоподобие в тренировочном множестве пропорционально:\n",
    "\n",
    "$$\\prod_i q_i^{N \\cdot p_i}$$\n",
    "\n",
    "тогда логарифм правдоподобия (log-likelihood) деленный на $N$ это:\n",
    "\n",
    "$$\\frac{1}{N} \\log \\prod_i q_i^{N p_i} = \\sum_i p_i \\log q_i = -H(p, q)$$\n",
    "\n",
    "таким образом максимизация правдоподобия происходит при минимизации функции перекрестной энтропии (cross entropy), определяемой для дискретных случайных величин $p$ и $q$ по формуле:\n",
    "\n",
    "$$H(p,q) = -\\sum_{x\\in\\mathcal{X}} p(x)\\, \\log q(x)$$\n",
    "\n",
    "\n",
    "Т.к. в реализации задач оптимизации принято искать параметры модели, при которых достигается минимум (в нашем случае - минимум функции потерь), то обычно минимзируют функцию потерь Negative Log-likelihood:\n",
    "\n",
    "$$\\mathcal{L} = - \\sum_i p_i \\log q_i = H(p, q)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Логистическая регрессия__\n",
    "\n",
    "* Рассмотрим случай __логистической регресии__ которая используется для классификации наблюдений на два класса, обозначим их $0$ и $1$.\n",
    "* Результат модели для наблюдения, представленного вектором факторов (features) $\\mathbf{x}$, может быть интерпретирован как вероятность отнесения наблюдения к одному из классов. Для этого используется  __логистическая функция__: $\\sigma(z)=1/(1+e^{-z})$. \n",
    "\n",
    "<center>     \n",
    "    <img src=\"./img03/1920px-Logistic-curve.svg.png\" alt=\"Предобработка данных\" style=\"width: 250px;\"/>\n",
    "    <strong>Предобработка данных</strong>\n",
    "</center>\n",
    "\n",
    "\n",
    "При этом $z$ это результат преобразования входного вектора $\\mathbf{x}$, чаще всего реализуемого с помощью линейной функции: $z = \\mathbf{w}\\cdot\\mathbf{x}$.\n",
    "* Тогда:\n",
    "    * веротяноть значения $y=1$ для наблюдения $\\mathbf{x}$:\n",
    "$$q_{y=1}\\ =\\ \\hat{y}\\ \\equiv\\ \\sigma (\\mathbf{w}\\cdot\\mathbf{x})\\ = 1/(1+e^{-\\mathbf{w}\\cdot\\mathbf{x}})$$\n",
    "    * и, соответственно, вероятность значения $y=0$:\n",
    "$$q_{y=0}\\ =\\ 1-\\hat{y}$$\n",
    "\n",
    "* <em class=\"ex\"></em> Например, мы имеем $N$ наблюдений имеющих индексы $n=1,\\dots,N$ и линейную функцию преобразования входного вектора, тогда среднее значение функции потерь:\n",
    "\n",
    "$$\\begin{align}\n",
    "    \\mathcal{L}(\\mathbf{w})\\ &=\\ \\frac1N\\sum_{n=1}^N H(p_n,q_n)\\ =\\ -\\frac1N\\sum_{n=1}^N\\ \\bigg[y_n  \\log \\hat y_n + (1 - y_n)  \\log (1 - \\hat y_n)\\bigg]\\,,\n",
    "\\end{align}$$\n",
    "\n",
    "где при использовании ленейной функции преобразования имеем $\\hat{y}_n = \\sigma(z) = \\sigma(\\mathbf{w}\\cdot\\mathbf{x}_n) = 1/(1+e^{-\\mathbf{w}\\cdot\\mathbf{x}_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.3000614e+01, 2.3363481e+00, 2.3665185e+00, 1.9494946e+01,\n",
       "        9.9741570e+01, 2.2951121e+00, 2.0292699e+00, 3.6185396e-01,\n",
       "        1.5908992e+00, 5.0580897e+00, 9.5744956e-01, 2.6116843e+00,\n",
       "        7.4689325e+02], dtype=float32),\n",
       " array([8.0954307e-01, 1.1140037e+00, 2.7357230e-01, 3.3301697e+00,\n",
       "        1.4242310e+01, 6.2409055e-01, 9.9604911e-01, 1.2410324e-01,\n",
       "        5.7074893e-01, 2.3117647e+00, 2.2792861e-01, 7.0799321e-01,\n",
       "        3.1402167e+02], dtype=float32))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_mean, wine_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Решаем задачу двухклассовой классификации__\n",
    "\n",
    "Используем:\n",
    "* результат $z$ преобразования входного вектора $\\mathbf{x}$, (чаще всего реализуемого с помощью линейной функции: $z = \\mathbf{w}\\cdot\\mathbf{x}$) направляем на сигмоиду: https://pytorch.org/docs/master/generated/torch.nn.Sigmoid.html\n",
    "* В качестве функции ошибки используем Binary Cross Entropy: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss , используем усреднение по мини батчу (значение по умолчанию для параметра reduction = 'mean')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:13, hidden_size:50, num_classes:2\n",
      "Epoch [1/30], Step [2/45], Loss: 0.6712\n",
      "Epoch [1/30], Step [4/45], Loss: 0.7114\n",
      "Epoch [1/30], Step [6/45], Loss: 0.6287\n",
      "Epoch [1/30], Step [8/45], Loss: 0.6647\n",
      "Epoch [2/30], Step [2/45], Loss: 0.6107\n",
      "Epoch [2/30], Step [4/45], Loss: 0.6127\n",
      "Epoch [2/30], Step [6/45], Loss: 0.5520\n",
      "Epoch [2/30], Step [8/45], Loss: 0.6235\n",
      "Epoch [3/30], Step [2/45], Loss: 0.5520\n",
      "Epoch [3/30], Step [4/45], Loss: 0.5280\n",
      "Epoch [3/30], Step [6/45], Loss: 0.5445\n",
      "Epoch [3/30], Step [8/45], Loss: 0.5441\n",
      "Epoch [4/30], Step [2/45], Loss: 0.4312\n",
      "Epoch [4/30], Step [4/45], Loss: 0.4813\n",
      "Epoch [4/30], Step [6/45], Loss: 0.5055\n",
      "Epoch [4/30], Step [8/45], Loss: 0.4973\n",
      "Epoch [5/30], Step [2/45], Loss: 0.4854\n",
      "Epoch [5/30], Step [4/45], Loss: 0.4158\n",
      "Epoch [5/30], Step [6/45], Loss: 0.3917\n",
      "Epoch [5/30], Step [8/45], Loss: 0.4909\n",
      "Epoch [6/30], Step [2/45], Loss: 0.4005\n",
      "Epoch [6/30], Step [4/45], Loss: 0.4004\n",
      "Epoch [6/30], Step [6/45], Loss: 0.3797\n",
      "Epoch [6/30], Step [8/45], Loss: 0.4203\n",
      "Epoch [7/30], Step [2/45], Loss: 0.3016\n",
      "Epoch [7/30], Step [4/45], Loss: 0.3867\n",
      "Epoch [7/30], Step [6/45], Loss: 0.3880\n",
      "Epoch [7/30], Step [8/45], Loss: 0.3301\n",
      "Epoch [8/30], Step [2/45], Loss: 0.3577\n",
      "Epoch [8/30], Step [4/45], Loss: 0.3299\n",
      "Epoch [8/30], Step [6/45], Loss: 0.2492\n",
      "Epoch [8/30], Step [8/45], Loss: 0.2821\n",
      "Epoch [9/30], Step [2/45], Loss: 0.3408\n",
      "Epoch [9/30], Step [4/45], Loss: 0.2478\n",
      "Epoch [9/30], Step [6/45], Loss: 0.2679\n",
      "Epoch [9/30], Step [8/45], Loss: 0.2768\n",
      "Epoch [10/30], Step [2/45], Loss: 0.2211\n",
      "Epoch [10/30], Step [4/45], Loss: 0.2605\n",
      "Epoch [10/30], Step [6/45], Loss: 0.2302\n",
      "Epoch [10/30], Step [8/45], Loss: 0.2824\n",
      "Epoch [11/30], Step [2/45], Loss: 0.2091\n",
      "Epoch [11/30], Step [4/45], Loss: 0.2256\n",
      "Epoch [11/30], Step [6/45], Loss: 0.2436\n",
      "Epoch [11/30], Step [8/45], Loss: 0.2356\n",
      "Epoch [12/30], Step [2/45], Loss: 0.1857\n",
      "Epoch [12/30], Step [4/45], Loss: 0.1796\n",
      "Epoch [12/30], Step [6/45], Loss: 0.1773\n",
      "Epoch [12/30], Step [8/45], Loss: 0.1909\n",
      "Epoch [13/30], Step [2/45], Loss: 0.2265\n",
      "Epoch [13/30], Step [4/45], Loss: 0.1577\n",
      "Epoch [13/30], Step [6/45], Loss: 0.1359\n",
      "Epoch [13/30], Step [8/45], Loss: 0.2231\n",
      "Epoch [14/30], Step [2/45], Loss: 0.2170\n",
      "Epoch [14/30], Step [4/45], Loss: 0.1174\n",
      "Epoch [14/30], Step [6/45], Loss: 0.1694\n",
      "Epoch [14/30], Step [8/45], Loss: 0.1925\n",
      "Epoch [15/30], Step [2/45], Loss: 0.1461\n",
      "Epoch [15/30], Step [4/45], Loss: 0.1263\n",
      "Epoch [15/30], Step [6/45], Loss: 0.0800\n",
      "Epoch [15/30], Step [8/45], Loss: 0.1567\n",
      "Epoch [16/30], Step [2/45], Loss: 0.1276\n",
      "Epoch [16/30], Step [4/45], Loss: 0.2273\n",
      "Epoch [16/30], Step [6/45], Loss: 0.1215\n",
      "Epoch [16/30], Step [8/45], Loss: 0.1180\n",
      "Epoch [17/30], Step [2/45], Loss: 0.2041\n",
      "Epoch [17/30], Step [4/45], Loss: 0.0767\n",
      "Epoch [17/30], Step [6/45], Loss: 0.1224\n",
      "Epoch [17/30], Step [8/45], Loss: 0.0840\n",
      "Epoch [18/30], Step [2/45], Loss: 0.0915\n",
      "Epoch [18/30], Step [4/45], Loss: 0.1635\n",
      "Epoch [18/30], Step [6/45], Loss: 0.1656\n",
      "Epoch [18/30], Step [8/45], Loss: 0.0777\n",
      "Epoch [19/30], Step [2/45], Loss: 0.1208\n",
      "Epoch [19/30], Step [4/45], Loss: 0.0892\n",
      "Epoch [19/30], Step [6/45], Loss: 0.0496\n",
      "Epoch [19/30], Step [8/45], Loss: 0.0751\n",
      "Epoch [20/30], Step [2/45], Loss: 0.0861\n",
      "Epoch [20/30], Step [4/45], Loss: 0.0552\n",
      "Epoch [20/30], Step [6/45], Loss: 0.1241\n",
      "Epoch [20/30], Step [8/45], Loss: 0.1276\n",
      "Epoch [21/30], Step [2/45], Loss: 0.1021\n",
      "Epoch [21/30], Step [4/45], Loss: 0.1256\n",
      "Epoch [21/30], Step [6/45], Loss: 0.0930\n",
      "Epoch [21/30], Step [8/45], Loss: 0.0624\n",
      "Epoch [22/30], Step [2/45], Loss: 0.1094\n",
      "Epoch [22/30], Step [4/45], Loss: 0.0501\n",
      "Epoch [22/30], Step [6/45], Loss: 0.1040\n",
      "Epoch [22/30], Step [8/45], Loss: 0.0563\n",
      "Epoch [23/30], Step [2/45], Loss: 0.0691\n",
      "Epoch [23/30], Step [4/45], Loss: 0.1250\n",
      "Epoch [23/30], Step [6/45], Loss: 0.0833\n",
      "Epoch [23/30], Step [8/45], Loss: 0.0756\n",
      "Epoch [24/30], Step [2/45], Loss: 0.0641\n",
      "Epoch [24/30], Step [4/45], Loss: 0.0859\n",
      "Epoch [24/30], Step [6/45], Loss: 0.0726\n",
      "Epoch [24/30], Step [8/45], Loss: 0.0487\n",
      "Epoch [25/30], Step [2/45], Loss: 0.0573\n",
      "Epoch [25/30], Step [4/45], Loss: 0.0665\n",
      "Epoch [25/30], Step [6/45], Loss: 0.0563\n",
      "Epoch [25/30], Step [8/45], Loss: 0.0776\n",
      "Epoch [26/30], Step [2/45], Loss: 0.0670\n",
      "Epoch [26/30], Step [4/45], Loss: 0.0538\n",
      "Epoch [26/30], Step [6/45], Loss: 0.0617\n",
      "Epoch [26/30], Step [8/45], Loss: 0.0548\n",
      "Epoch [27/30], Step [2/45], Loss: 0.0576\n",
      "Epoch [27/30], Step [4/45], Loss: 0.1498\n",
      "Epoch [27/30], Step [6/45], Loss: 0.0453\n",
      "Epoch [27/30], Step [8/45], Loss: 0.0290\n",
      "Epoch [28/30], Step [2/45], Loss: 0.0448\n",
      "Epoch [28/30], Step [4/45], Loss: 0.0430\n",
      "Epoch [28/30], Step [6/45], Loss: 0.0936\n",
      "Epoch [28/30], Step [8/45], Loss: 0.0268\n",
      "Epoch [29/30], Step [2/45], Loss: 0.1008\n",
      "Epoch [29/30], Step [4/45], Loss: 0.0483\n",
      "Epoch [29/30], Step [6/45], Loss: 0.1057\n",
      "Epoch [29/30], Step [8/45], Loss: 0.0234\n",
      "Epoch [30/30], Step [2/45], Loss: 0.0205\n",
      "Epoch [30/30], Step [4/45], Loss: 0.0765\n",
      "Epoch [30/30], Step [6/45], Loss: 0.0271\n",
      "Epoch [30/30], Step [8/45], Loss: 0.0433\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# parameters:\n",
    "positive_class_label = 3.0\n",
    "\n",
    "# Hyper-parameters #1\n",
    "batch_size = 20\n",
    "shuffle_dataset = True\n",
    "\n",
    "class TwoClass:\n",
    "    def __init__(self, positive_label, inplace=False):\n",
    "        self.positive_label = positive_label\n",
    "\n",
    "    def __call__(self, sample):                \n",
    "        inputs, targets = sample\n",
    "        targets_tc = torch.empty(targets.size())\n",
    "        targets_tc[targets == self.positive_label] = 1.0\n",
    "        targets_tc[targets != self.positive_label] = 0.0   \n",
    "#         print(inputs, targets_tc)\n",
    "        return inputs, targets_tc\n",
    "\n",
    "\n",
    "composed_tfms = transforms.Compose([\n",
    "            ToTensor(), \n",
    "            Normalize(wine_mean, wine_std),\n",
    "            TwoClass(positive_label=positive_class_label)\n",
    "        ])\n",
    "\n",
    "train_ds = WineDataset(transform=composed_tfms)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle_dataset)\n",
    "\n",
    "\n",
    "# Get features size:\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()\n",
    "# print(f'data: {data}')\n",
    "# features, labels = data\n",
    "inputs, targets = data\n",
    "\n",
    "# Hyper-parameters #2\n",
    "input_size = inputs.shape[1] # use features size\n",
    "hidden_size = 50\n",
    "num_classes = 2\n",
    "print(f'input_size:{input_size}, hidden_size:{hidden_size}, num_classes:{num_classes}')\n",
    "\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "# print('inputs:', inputs, features.shape)\n",
    "# print('targets:', targets, targets.shape)\n",
    "# ----------\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NNTwoClases(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NNTwoClases, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, 1) # класса 2 вероятность y^ - одна  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NNTwoClases(input_size, hidden_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# see: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)      \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, targets_) in enumerate(train_dl):\n",
    "        inputs = inputs.to(device)\n",
    "        targets_ = targets_.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "#         print(outputs, targets_)\n",
    "        loss = criterion(outputs, targets_)\n",
    "        \n",
    "        # zero grad before new step        \n",
    "        optimizer.zero_grad()                \n",
    "        # Backward and optimize        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        if (i+1) % 2 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Добавляем train/test split__:\n",
    "\n",
    "Разделим данные на training и test с использованием классов `SubsetRandomSampler` и `DataLoader`.\n",
    "\n",
    "`DataLoader` подгружает данные, предоставляемые классом `Dataset`, во время тренировки и группирует их в батчи.\n",
    "Он дает возможность указать `Sampler` (в нашем случае `SubsetRandomSampler`), который выбирает, какие примеры из датасета использовать для тренировки. Мы используем это, чтобы разделить данные на training и test.\n",
    "\n",
    "Подробнее: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = list(range(178))\n",
    "# validation_split = .2\n",
    "# random_seed= 42\n",
    "# shuffle_dataset = True\n",
    "\n",
    "# dataset_size = len(dataset)\n",
    "# indices = list(range(dataset_size))\n",
    "# split = int(np.floor(validation_split * dataset_size))\n",
    "# if shuffle_dataset :\n",
    "#     np.random.seed(random_seed)\n",
    "#     np.random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# # train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# parameters:\n",
    "positive_class_label = 3.0\n",
    "\n",
    "# Hyper-parameters #1\n",
    "batch_size = 20\n",
    "test_split = .2\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "\n",
    "composed_tfms = transforms.Compose([\n",
    "            ToTensor(), \n",
    "            Normalize(wine_mean, wine_std),\n",
    "            TwoClass(positive_label=positive_class_label)\n",
    "        ])\n",
    "\n",
    "dataset = WineDataset(transform=composed_tfms)\n",
    "\n",
    "# Creating data indices for training and test splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "test_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)\n",
    "\n",
    "# Get inputs(features) size:\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()\n",
    "# features, labels = data\n",
    "inputs, targets = data\n",
    "# print(f'inputs: {inputs.shape}, {inputs}, targets: {targets.shape}, {targets}')\n",
    "\n",
    "# parameters:\n",
    "dataset_num_classes = 2\n",
    "dataset_input_size = inputs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_indices), len(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:13, hidden_size:50, num_classes:2\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "# Hyper-parameters #2\n",
    "input_size = dataset_input_size # use inputs size\n",
    "hidden_size = 50 # 20 | 50\n",
    "num_classes = dataset_num_classes # 2\n",
    "print(f'input_size:{input_size}, hidden_size:{hidden_size}, num_classes:{num_classes}')\n",
    "\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NNTwoClases(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NNTwoClases, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() # on|off\n",
    "        self.l2 = nn.Linear(hidden_size, 1) # класса 2 вероятность y^ - одна  \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out) # on|off\n",
    "        out = self.l2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "model = NNTwoClases(input_size, hidden_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# see: https://pytorch.org/docs/stable/nn.html#torch.nn.BCELoss\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE NETWORK\n",
    "def train(model, device, train_dl, optimizer):\n",
    "    #set model in train() mode:\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets) \n",
    "        \n",
    "        # Backward and optimize        \n",
    "        # zero grad before new step        \n",
    "        optimizer.zero_grad()                        \n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "\n",
    "        # calculating the total_loss for checking\n",
    "        total_loss += loss           \n",
    "        \n",
    "        # PREDICTIONS \n",
    "        total_samples += targets.shape[0]    \n",
    "        predictions = outputs.round()\n",
    "        correct_samples += torch.sum(predictions==targets)\n",
    "#         if i ==0:\n",
    "#             print(f'outputs: {outputs}, predictions:{predictions}, targets:{targets}, correct_samples:{correct_samples}')        \n",
    "        \n",
    "    train_accuracy = float(correct_samples) / total_samples        \n",
    "    \n",
    "    return total_loss, train_accuracy                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING THE MODEL\n",
    "def test(model, device, test_dl):\n",
    "    #set model in eval() mode (it skips Dropout etc):\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0 \n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(test_dl):\n",
    "            #LOAD THE DATA IN A BATCH            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)            \n",
    "                       \n",
    "            # apply model to input data\n",
    "            outputs = model(inputs)        \n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            total_samples += targets.shape[0]    \n",
    "            predictions = outputs.round()\n",
    "            correct_samples += torch.sum(predictions==targets)        \n",
    "        \n",
    "    test_accuracy = correct_samples / total_samples        \n",
    "    \n",
    "    return test_accuracy              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 5.3182, Train acc: 0.6503, Test acc: 0.7143\n",
      "Epoch [2/60], Loss: 4.7288, Train acc: 0.7762, Test acc: 0.7429\n",
      "Epoch [3/60], Loss: 4.4194, Train acc: 0.8182, Test acc: 0.7714\n",
      "Epoch [4/60], Loss: 4.0325, Train acc: 0.8601, Test acc: 0.8286\n",
      "Epoch [5/60], Loss: 3.6260, Train acc: 0.8881, Test acc: 0.9143\n",
      "Epoch [6/60], Loss: 3.6172, Train acc: 0.9021, Test acc: 0.9429\n",
      "Epoch [7/60], Loss: 3.1916, Train acc: 0.9021, Test acc: 0.9429\n",
      "Epoch [8/60], Loss: 2.9085, Train acc: 0.9091, Test acc: 0.9429\n",
      "Epoch [9/60], Loss: 2.8734, Train acc: 0.9301, Test acc: 0.9429\n",
      "Epoch [10/60], Loss: 2.5183, Train acc: 0.9371, Test acc: 0.9714\n",
      "Epoch [11/60], Loss: 2.1968, Train acc: 0.9510, Test acc: 0.9714\n",
      "Epoch [12/60], Loss: 2.0326, Train acc: 0.9580, Test acc: 0.9714\n",
      "Epoch [13/60], Loss: 1.9018, Train acc: 0.9650, Test acc: 0.9714\n",
      "Epoch [14/60], Loss: 1.7000, Train acc: 0.9650, Test acc: 0.9714\n",
      "Epoch [15/60], Loss: 1.6616, Train acc: 0.9720, Test acc: 0.9714\n",
      "Epoch [16/60], Loss: 1.5854, Train acc: 0.9790, Test acc: 0.9714\n",
      "Epoch [17/60], Loss: 1.3538, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [18/60], Loss: 1.1648, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [19/60], Loss: 1.0776, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [20/60], Loss: 1.1076, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [21/60], Loss: 0.9760, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [22/60], Loss: 0.8767, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [23/60], Loss: 1.0474, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [24/60], Loss: 0.9163, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [25/60], Loss: 0.7296, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [26/60], Loss: 0.7032, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [27/60], Loss: 0.6133, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [28/60], Loss: 0.5814, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [29/60], Loss: 0.5815, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [30/60], Loss: 0.5646, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [31/60], Loss: 0.6144, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [32/60], Loss: 0.4813, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [33/60], Loss: 0.5821, Train acc: 0.9860, Test acc: 0.9714\n",
      "Epoch [34/60], Loss: 0.4495, Train acc: 0.9860, Test acc: 1.0000\n",
      "Epoch [35/60], Loss: 0.6028, Train acc: 0.9860, Test acc: 1.0000\n",
      "Epoch [36/60], Loss: 0.4180, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [37/60], Loss: 0.3845, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [38/60], Loss: 0.5209, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [39/60], Loss: 0.3656, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [40/60], Loss: 0.3397, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [41/60], Loss: 0.3800, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [42/60], Loss: 0.3040, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [43/60], Loss: 0.2904, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [44/60], Loss: 0.2877, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [45/60], Loss: 0.2750, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [46/60], Loss: 0.3067, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [47/60], Loss: 0.2607, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [48/60], Loss: 0.2492, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [49/60], Loss: 0.2376, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [50/60], Loss: 0.2385, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [51/60], Loss: 0.2451, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [52/60], Loss: 0.2313, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [53/60], Loss: 0.2584, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [54/60], Loss: 0.2732, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [55/60], Loss: 0.2116, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [56/60], Loss: 0.1972, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [57/60], Loss: 0.1896, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [58/60], Loss: 0.1978, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [59/60], Loss: 0.2632, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [60/60], Loss: 0.1711, Train acc: 0.9930, Test acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, train_accuracy = train(model, device, train_dl, optimizer)\n",
    "    test_accuracy = test(model, device, test_dl)\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Train acc: {train_accuracy:.4f}, Test acc: {test_accuracy:.4f}')                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Обобщение на задачу многоклассовой классификации__\n",
    "\n",
    "* <em class=\"df\"></em> Функяия __softmax__ (или _normalized exponential function_) — это обобщение логистической функции для многомерного случая. \n",
    "    * Функция преобразует вектор $\\mathbf{z}$ размерности $K$ в вектор $\\mathbf{\\sigma}$ той же размерности, где каждая координата $\\sigma_i$ полученного вектора представлена вещественным числом в интервале $[0,1]$:\n",
    "$$\\mathbf{\\sigma}(\\mathbf{z})_i = \\frac{e^{z_i}}{\\displaystyle\\sum_{k \\mathop =1}^K e^{z_k}}$$\n",
    "    * Легко показать, что:\n",
    "        * сумма координат равна $\\sum_{k \\mathop =1}^K \\mathbf{\\sigma}(\\mathbf{z})_k = 1$.\n",
    "        * и каждое из значений $\\sigma(\\mathbf{z})_i \\in [0,1]$.\n",
    "    * Таким образом, функция берет на вход вектор $\\mathbf{z}$ содержащий значения, которые могут выходить за интервал $[0,1]$ преобразуя их вектор $\\mathbf{\\sigma}$, который может рассматриваться как вероятности $K$ значений дискретной случайной величины.\n",
    "    * При этом, наибольшее значение среди $K$ компонент вектора $\\mathbf{z}$ осатется наибольшей в векторе $\\mathbf{\\sigma}$ (соотношение максимального компонента к остальным увеличвиается т.к.: $\\mathbf{\\sigma}(\\mathbf{z})_i/\\mathbf{\\sigma}(\\mathbf{z})_j = e^{z_i-z_j}>1$, если $z_i>z_j$\n",
    "\n",
    "\n",
    "* Применяя softmax в функции потерь negative log-likelihood получим:\n",
    "\n",
    "$$\\mathcal{L} = - \\sum_i p_i \\log q_i = - \\sum_{n=1}^N \\sum_{k=1}^K t_{nk}\\ln y_{nk} = - \\sum_{n=1}^N \\sum_{k=1}^K t_{nk} \\frac{e^{z_{nk}}}{\\displaystyle\\sum_{i \\mathop =1}^K e^{z_{ni}}}= - \\sum_{n=1}^N \\frac{e^{z_{n k(n)}}}{\\displaystyle\\sum_{i \\mathop =1}^K e^{z_{ni}}}$$\n",
    "\n",
    "где, при использовании ленейной функции преобразования входного вектора $\\mathbf{x}$ в $z$, имеем $z_{nk} = \\sigma(\\mathbf{w}_k\\cdot\\mathbf{x}_n) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters #1\n",
    "batch_size = 20\n",
    "validation_split = .2\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "\n",
    "composed_tfms = transforms.Compose([\n",
    "            ToTensor(), \n",
    "            Normalize(wine_mean, wine_std) # without TwoClass\n",
    "        ])\n",
    "\n",
    "dataset = WineDataset(transform=composed_tfms)\n",
    "\n",
    "# Creating data indices for training and test splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "test_dl = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)\n",
    "\n",
    "# Get inputs(features) size:\n",
    "dataiter = iter(train_dl)\n",
    "data = dataiter.next()\n",
    "# features, labels = data\n",
    "inputs, targets = data\n",
    "# print(f'inputs: {inputs.shape}, {inputs}, targets: {targets.shape}, {targets}')\n",
    "\n",
    "# parameters:\n",
    "dataset_num_classes = 3\n",
    "dataset_input_size = inputs.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__Решаем задачу многоклассовой классификации__\n",
    "\n",
    "* Используем CrossEntropyLoss: https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "    * This criterion combines `nn.LogSoftmax()` and `nn.NLLLoss()` in one single class.\n",
    "    * Input: (N, C)(N,C) where C = number of classes\n",
    "    * Target: (N)(N) where each value is 0 \\leq \\text{targets}[i] \\leq C-10≤targets[i]≤C−1\n",
    "    * Default: `reduction='mean'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:13, hidden_size:50, num_classes:3\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "# Hyper-parameters #2\n",
    "input_size = dataset_input_size # use inputs(features) size\n",
    "hidden_size = 50 \n",
    "num_classes = dataset_num_classes # (не можем получить из минибатча)\n",
    "print(f'input_size:{input_size}, hidden_size:{hidden_size}, num_classes:{num_classes}')\n",
    "\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NClases(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes): # new parameter: num_classes\n",
    "        super(NClases, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() # on|off\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out) # on|off\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end        \n",
    "        return out\n",
    "\n",
    "model = NClases(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `torch.max()`: `torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)`\n",
    "    * parameters:\n",
    "        * `input (Tensor)` – the input tensor.\n",
    "        * `dim (int)` – the dimension to reduce.\n",
    "        * `keepdim (bool)` – whether the output tensor has dim retained or not. Default: False.\n",
    "        * `out (tuple, optional)` – the result tuple of two output tensors (max, max_indices)\n",
    "    * returns namedtuple `(values, indices)`\n",
    "        *  `values` is the maximum value of each row of the input tensor in the given dimension dim. \n",
    "        *  `indices` is the index location of each maximum value found (argmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE NETWORK\n",
    "def train(model, device, train_dl, optimizer):\n",
    "    #set model in train() mode:\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        targets = targets.squeeze().to(torch.long)-1 # target mast be 1-D tensor\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.squeeze()) \n",
    "        \n",
    "        # Backward and optimize        \n",
    "        # zero grad before new step        \n",
    "        optimizer.zero_grad()                        \n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "\n",
    "        # calculating the total_loss for checking\n",
    "        total_loss += loss           \n",
    "        \n",
    "        # PREDICTIONS \n",
    "        total_samples += targets.shape[0]   \n",
    "        _, predictions_indices = torch.max(outputs, 1) # dim=1 - dimension to reduce\n",
    "        correct_samples += torch.sum(predictions_indices==targets)\n",
    "#         if i == 0:\n",
    "#             print(f'outputs: {outputs}, predictions_indices:{predictions_indices}, \\\n",
    "#             targets:{targets}, correct_samples:{correct_samples}, total_samples: {total_samples}')        \n",
    "        \n",
    "    train_accuracy = float(correct_samples) / total_samples        \n",
    "    \n",
    "    return total_loss, train_accuracy                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING THE MODEL\n",
    "def test(model, device, test_dl):\n",
    "    #set model in eval() mode (it skips Dropout etc):\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0 \n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(test_dl):\n",
    "            #LOAD THE DATA IN A BATCH            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)   \n",
    "            targets = targets.squeeze().to(torch.long)-1 # target mast be 1-D tensor           \n",
    "                       \n",
    "            # apply model to input data\n",
    "            outputs = model(inputs)        \n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            total_samples += targets.shape[0]   \n",
    "            _, predictions_indices = torch.max(outputs, 1) # dim=1 - dimension to reduce\n",
    "            correct_samples += torch.sum(predictions_indices==targets)                    \n",
    "        \n",
    "    test_accuracy = correct_samples / total_samples        \n",
    "    \n",
    "    return test_accuracy              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60], Loss: 8.3143, Train acc: 0.4825, Test acc: 0.7429\n",
      "Epoch [2/60], Loss: 7.3919, Train acc: 0.8042, Test acc: 0.8571\n",
      "Epoch [3/60], Loss: 6.5464, Train acc: 0.8951, Test acc: 0.8571\n",
      "Epoch [4/60], Loss: 5.7520, Train acc: 0.9091, Test acc: 0.8571\n",
      "Epoch [5/60], Loss: 5.3157, Train acc: 0.9091, Test acc: 0.9143\n",
      "Epoch [6/60], Loss: 4.9220, Train acc: 0.9231, Test acc: 0.9143\n",
      "Epoch [7/60], Loss: 4.4294, Train acc: 0.9371, Test acc: 0.9429\n",
      "Epoch [8/60], Loss: 3.9253, Train acc: 0.9510, Test acc: 0.9429\n",
      "Epoch [9/60], Loss: 3.3911, Train acc: 0.9510, Test acc: 0.9429\n",
      "Epoch [10/60], Loss: 3.2573, Train acc: 0.9510, Test acc: 0.9429\n",
      "Epoch [11/60], Loss: 2.9671, Train acc: 0.9580, Test acc: 0.9429\n",
      "Epoch [12/60], Loss: 2.5127, Train acc: 0.9580, Test acc: 0.9429\n",
      "Epoch [13/60], Loss: 2.3189, Train acc: 0.9650, Test acc: 0.9429\n",
      "Epoch [14/60], Loss: 2.0299, Train acc: 0.9650, Test acc: 0.9714\n",
      "Epoch [15/60], Loss: 1.8149, Train acc: 0.9650, Test acc: 0.9714\n",
      "Epoch [16/60], Loss: 1.6294, Train acc: 0.9720, Test acc: 0.9714\n",
      "Epoch [17/60], Loss: 1.5068, Train acc: 0.9790, Test acc: 0.9714\n",
      "Epoch [18/60], Loss: 1.3995, Train acc: 0.9790, Test acc: 0.9714\n",
      "Epoch [19/60], Loss: 1.5434, Train acc: 0.9790, Test acc: 0.9714\n",
      "Epoch [20/60], Loss: 1.1413, Train acc: 0.9790, Test acc: 0.9714\n",
      "Epoch [21/60], Loss: 1.0740, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [22/60], Loss: 0.9510, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [23/60], Loss: 0.9937, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [24/60], Loss: 0.8519, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [25/60], Loss: 0.8046, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [26/60], Loss: 0.7866, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [27/60], Loss: 0.6915, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [28/60], Loss: 0.8683, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [29/60], Loss: 0.6122, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [30/60], Loss: 0.5680, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [31/60], Loss: 0.5934, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [32/60], Loss: 0.5233, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [33/60], Loss: 0.5782, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [34/60], Loss: 0.5733, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [35/60], Loss: 0.4481, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [36/60], Loss: 0.4487, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [37/60], Loss: 0.4287, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [38/60], Loss: 0.4102, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [39/60], Loss: 0.3772, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [40/60], Loss: 0.3884, Train acc: 0.9930, Test acc: 0.9714\n",
      "Epoch [41/60], Loss: 0.3468, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [42/60], Loss: 0.3500, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [43/60], Loss: 0.3413, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [44/60], Loss: 0.3111, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [45/60], Loss: 0.3136, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [46/60], Loss: 0.2900, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [47/60], Loss: 0.2830, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [48/60], Loss: 0.2791, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [49/60], Loss: 0.4991, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [50/60], Loss: 0.3454, Train acc: 0.9930, Test acc: 1.0000\n",
      "Epoch [51/60], Loss: 0.2493, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [52/60], Loss: 0.2378, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [53/60], Loss: 0.2398, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [54/60], Loss: 0.2458, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [55/60], Loss: 0.2351, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [56/60], Loss: 0.2439, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [57/60], Loss: 0.2046, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [58/60], Loss: 0.2022, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [59/60], Loss: 0.1882, Train acc: 1.0000, Test acc: 1.0000\n",
      "Epoch [60/60], Loss: 0.2012, Train acc: 1.0000, Test acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, train_accuracy = train(model, device, train_dl, optimizer)\n",
    "    test_accuracy = test(model, device, test_dl)\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Train acc: {train_accuracy:.4f}, Test acc: {test_accuracy:.4f}')                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__Многоклассовая классификация на датасете MNIST__\n",
    "\n",
    "https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "<center>     \n",
    "    <img src=\"./img03/MnistExamples.png\" alt=\"Примеры изображений из MNIST\" style=\"width: 500px;\"/>\n",
    "    <strong>Примеры изображений из MNIST</strong>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# parameters:\n",
    "positive_class_label = 3.0\n",
    "\n",
    "# Hyper-parameters #1\n",
    "batch_size = 100 # big batches\n",
    "validation_split = .2\n",
    "random_seed= 42\n",
    "shuffle_dataset = True\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "train_batch_qty = math.ceil(len(train_dataset)/batch_size)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "test_batch_qty = math.ceil(len(test_dataset)/batch_size)\n",
    "\n",
    "# Data loader\n",
    "train_dl = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=shuffle_dataset)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# # Get inputs(features) size:\n",
    "# dataiter = iter(train_dl)\n",
    "# data = dataiter.next()\n",
    "# # features, labels = data\n",
    "# inputs, targets = data\n",
    "# # print(f'inputs: {inputs.shape}, {inputs}, targets: {targets.shape}, {targets}')\n",
    "\n",
    "# parameters:\n",
    "dataset_num_classes = 10\n",
    "# dataset_input_size = inputs.shape[1]\n",
    "dataset_input_size = 28 * 28 # 28x28=784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size:784, hidden_size:500, num_classes:10\n"
     ]
    }
   ],
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "# Hyper-parameters #2\n",
    "input_size = dataset_input_size # use inputs(features) size\n",
    "hidden_size = 500 \n",
    "num_classes = dataset_num_classes # (не можем получить из минибатча)\n",
    "print(f'input_size:{input_size}, hidden_size:{hidden_size}, num_classes:{num_classes}')\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create fully connected neural network with one hidden layer:\n",
    "model = NClases(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  tqdm import tqdm\n",
    "# import tqdm.notebook.tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f003ecd533dc4d3db54b8b8a218e3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING THE NETWORK\n",
    "def train(model, device, train_dl, optimizer):\n",
    "    #set model in train() mode:\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0\n",
    "    \n",
    "    for i, (inputs, targets) in tqdm(enumerate(train_dl), total=train_batch_qty, desc='Training minibatch loop '):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)        \n",
    "        inputs = inputs.reshape(-1, 28*28).to(device)\n",
    "#         print(inputs.size(), targets.size(), targets)\n",
    "#         assert False\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.squeeze()) \n",
    "        \n",
    "        # Backward and optimize        \n",
    "        # zero grad before new step        \n",
    "        optimizer.zero_grad()                        \n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "\n",
    "        # calculating the total_loss for checking\n",
    "        total_loss += loss           \n",
    "        \n",
    "        # PREDICTIONS \n",
    "        total_samples += targets.shape[0]   \n",
    "        _, predictions_indices = torch.max(outputs, 1) # dim=1 - dimension to reduce\n",
    "        correct_samples += torch.sum(predictions_indices==targets)\n",
    "#         if i == 0:\n",
    "#             print(f'outputs: {outputs}, predictions_indices:{predictions_indices}, \\\n",
    "#             targets:{targets}, correct_samples:{correct_samples}, total_samples: {total_samples}')        \n",
    "        \n",
    "    train_accuracy = float(correct_samples) / total_samples        \n",
    "    \n",
    "    return total_loss, train_accuracy                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING THE MODEL\n",
    "def test(model, device, test_dl):\n",
    "    #set model in eval() mode (it skips Dropout etc):\n",
    "    model.eval()\n",
    "    \n",
    "    total_samples = 0.0\n",
    "    correct_samples = 0.0 \n",
    "    \n",
    "    # set the requires_grad flag to false as we are in the test mode\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in tqdm(enumerate(test_dl), total=test_batch_qty, desc='Testing minibatch loop:'):\n",
    "            #LOAD THE DATA IN A BATCH                       \n",
    "            inputs, targets = inputs.to(device), targets.to(device)        \n",
    "            inputs = inputs.reshape(-1, 28*28).to(device)            \n",
    "                       \n",
    "            # apply model to input data\n",
    "            outputs = model(inputs)        \n",
    "                       \n",
    "            #PREDICTIONS\n",
    "            total_samples += targets.shape[0]   \n",
    "            _, predictions_indices = torch.max(outputs, 1) # dim=1 - dimension to reduce\n",
    "            correct_samples += torch.sum(predictions_indices==targets)                    \n",
    "        \n",
    "    test_accuracy = correct_samples / total_samples        \n",
    "    \n",
    "    return test_accuracy              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9b4f21f59b4cc5b9b03f63f639cad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe890657233e490c8067651167a266d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10], Loss: 173.0010, Train acc: 0.9209, Test acc: 0.9581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469b32117e144e9a9ac272cbe765169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17bf9f514fd426fa393a119a52caf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [2/10], Loss: 69.2540, Train acc: 0.9667, Test acc: 0.9677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8fd14cad4d43ea9f368b46850d69b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9fff32537e46b68adc659f6385998c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [3/10], Loss: 45.8252, Train acc: 0.9775, Test acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a64c2d2160f43299d34d67d0a0e504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47fe1263bd0c4ac793eb8df814b62316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [4/10], Loss: 33.1776, Train acc: 0.9836, Test acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ac4f1b7614d01a8e25bb15735f377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d68d91828dc4c22a380e1ccf08156a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [5/10], Loss: 24.6944, Train acc: 0.9879, Test acc: 0.9802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff6cee8a5e443abbbfbb9e335f60013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d21fc10a9943ca9df4050fc45614b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [6/10], Loss: 18.2698, Train acc: 0.9908, Test acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73fe1d898d24ca3a5fe6ab1ffe85457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0618f73fde4b028ed2b9e51dd86258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Testing minibatch loop:', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [7/10], Loss: 14.0210, Train acc: 0.9935, Test acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3953467cfa48475a83fae7529faf3ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training minibatch loop ', max=600.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-578-2213afe389ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_total_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Train acc: {train_accuracy:.4f}, Test acc: {test_accuracy:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-576-8f19e7113f14>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_dl, optimizer)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcorrect_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_batch_qty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training minibatch loop '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \"\"\"\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\pyTorch_1_5v2\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, train_accuracy = train(model, device, train_dl, optimizer)\n",
    "    test_accuracy = test(model, device, test_dl)\n",
    "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}, Train acc: {train_accuracy:.4f}, Test acc: {test_accuracy:.4f}')                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
